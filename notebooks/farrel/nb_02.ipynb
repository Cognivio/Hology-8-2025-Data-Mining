{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOmp6Rtqa964QT1UCkhX9GO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarrelAD/Hology-8-2025-Data-Mining-PRIVATE/blob/dev%2Ffarrel/notebooks/farrel/nb_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Project Setup"
      ],
      "metadata": {
        "id": "GICeS71CvUPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "xBfxBaeTvX8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejDz9bfpvLsX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from scipy.ndimage import gaussian_filter, maximum_filter\n",
        "from typing import Optional, Tuple, Dict, Any, Union\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "Yd0-0nGxvank"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configure Kaggle secret key\n",
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "4vlkw-BTvdtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Dataset in Colab\n",
        "import zipfile\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "zip_path = \"/content/penyisihan-hology-8-0-2025-data-mining.zip\"\n",
        "drive_extract_path = \"/content/drive/MyDrive/PROJECTS/Cognivio/Percobaan Hology 8 2025/dataset\"\n",
        "local_dataset_path = \"/content/dataset\"  # for current session\n",
        "\n",
        "# ---------------------------\n",
        "# Step 1: Download zip (if not exists in /content)\n",
        "# ---------------------------\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Dataset not found locally, downloading...\")\n",
        "    !kaggle competitions download -c penyisihan-hology-8-0-2025-data-mining -p /content\n",
        "else:\n",
        "    print(\"Dataset already exists, skipping download.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Step 2: Extract to Google Drive (for backup)\n",
        "# ---------------------------\n",
        "os.makedirs(drive_extract_path, exist_ok=True)\n",
        "\n",
        "if not os.listdir(drive_extract_path):  # Check if folder is empty\n",
        "    print(\"Extracting dataset to Google Drive...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(drive_extract_path)\n",
        "    print(\"Dataset extracted to:\", drive_extract_path)\n",
        "else:\n",
        "    print(\"Dataset already extracted at:\", drive_extract_path)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 3: Copy dataset to local /content (faster training)\n",
        "# ---------------------------\n",
        "if not os.path.exists(local_dataset_path):\n",
        "    print(\"Copying dataset to Colab local storage (/content)...\")\n",
        "    !cp -r \"$drive_extract_path\" \"$local_dataset_path\"\n",
        "else:\n",
        "    print(\"Dataset already available in Colab local storage.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Step 4: Define dataset paths for training\n",
        "# ---------------------------\n",
        "TRAIN_IMG_DIR = os.path.join(local_dataset_path, \"train\", \"images\")\n",
        "TRAIN_LBL_DIR = os.path.join(local_dataset_path, \"train\", \"labels\")\n",
        "TEST_IMG_DIR  = os.path.join(local_dataset_path, \"test\", \"images\")\n",
        "\n",
        "print(\"Train images:\", TRAIN_IMG_DIR)\n",
        "print(\"Train labels:\", TRAIN_LBL_DIR)\n",
        "print(\"Test images:\", TEST_IMG_DIR)"
      ],
      "metadata": {
        "id": "BkPqyNB0vilZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset and Density Map Generation"
      ],
      "metadata": {
        "id": "YJbhXWN1vjd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrowdCountingDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_dir: str,\n",
        "        label_dir: str,\n",
        "        max_samples: Optional[int] = None,\n",
        "        img_size: int = 224,\n",
        "        downscale_factor: int = 16,\n",
        "        sigma: float = 4.0,\n",
        "        transform: Optional[Any] = None,\n",
        "        return_meta: bool = False,\n",
        "        cache_density: bool = True,\n",
        "    ) -> None:\n",
        "        self.image_dir = image_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.img_size = img_size\n",
        "        self.downscale_factor = downscale_factor\n",
        "        self.sigma = sigma\n",
        "        self.transform = transform\n",
        "        self.return_meta = return_meta\n",
        "        self.cache_density = cache_density\n",
        "\n",
        "        # Collect image files\n",
        "        all_images = sorted([f for f in os.listdir(image_dir) if f.endswith(\".jpg\")])\n",
        "        if max_samples:\n",
        "            self.image_files = all_images[:max_samples]\n",
        "        else:\n",
        "            self.image_files = all_images\n",
        "\n",
        "        # Pre-load label jsons into memory (fast lookup)\n",
        "        self.labels = self._load_labels()\n",
        "\n",
        "        print(f\"Using {len(self.image_files)} images for training.\")\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(\n",
        "        self,\n",
        "        idx: int\n",
        "    ) -> Union[Tuple[torch.Tensor, torch.Tensor], Dict[str, Any]]:\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "\n",
        "        # ---- Load and resize image ----\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        orig_h, orig_w = image.shape[:2]\n",
        "        image = cv2.resize(image, (self.img_size, self.img_size))\n",
        "        image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
        "\n",
        "        if self.transform:\n",
        "            image_tensor = self.transform(image_tensor)\n",
        "\n",
        "        # ---- Get density map (cached or computed) ----\n",
        "        density_map = self._get_density_map(img_name, orig_w, orig_h)\n",
        "        density_map_tensor = torch.from_numpy(density_map).unsqueeze(0)\n",
        "\n",
        "        # Compute crowd count\n",
        "        count = float(density_map_tensor.sum())\n",
        "\n",
        "        if self.return_meta:\n",
        "            return {\n",
        "                \"image\": image_tensor,\n",
        "                \"density\": density_map_tensor,\n",
        "                \"count\": count,\n",
        "                \"name\": img_name,\n",
        "                \"orig_size\": (orig_h, orig_w),\n",
        "            }\n",
        "        else:\n",
        "            return image_tensor, density_map_tensor\n",
        "\n",
        "    def _load_labels(self) -> Dict[str, Dict[str, Any]]:\n",
        "        \"\"\"Load labels from JSON files into memory.\"\"\"\n",
        "        labels = {}\n",
        "        for img_file in self.image_files:\n",
        "            label_file = img_file.replace(\".jpg\", \".json\")\n",
        "            label_path = os.path.join(self.label_dir, label_file)\n",
        "            if os.path.exists(label_path):\n",
        "                with open(label_path, \"r\") as f:\n",
        "                    labels[img_file] = json.load(f)\n",
        "        return labels\n",
        "\n",
        "    def _get_density_map(self, img_name: str, orig_w: int, orig_h: int) -> np.ndarray:\n",
        "        \"\"\"Generate or load precomputed density map.\"\"\"\n",
        "        output_size = self.img_size // self.downscale_factor\n",
        "        cache_path = os.path.join(self.label_dir, img_name.replace(\".jpg\", \".npy\"))\n",
        "\n",
        "        # If cached density exists, just load\n",
        "        if self.cache_density and os.path.exists(cache_path):\n",
        "            return np.load(cache_path)\n",
        "\n",
        "        # Otherwise, compute density map\n",
        "        density_map = np.zeros((output_size, output_size), dtype=np.float32)\n",
        "        label_data = self.labels.get(img_name)\n",
        "\n",
        "        if label_data and label_data.get(\"human_num\", 0) > 0:\n",
        "            raw_points = label_data[\"points\"]\n",
        "\n",
        "            points = np.array([[p[\"x\"], p[\"y\"]] for p in raw_points], dtype=np.float32)\n",
        "\n",
        "            for x, y in points:\n",
        "                scaled_x = (x / orig_w) * output_size\n",
        "                scaled_y = (y / orig_h) * output_size\n",
        "                ix, iy = int(scaled_x), int(scaled_y)\n",
        "                if 0 <= ix < output_size and 0 <= iy < output_size:\n",
        "                    density_map[iy, ix] += 1.0\n",
        "\n",
        "        # Apply Gaussian filter\n",
        "        density_map = gaussian_filter(density_map, sigma=self.sigma / self.downscale_factor)\n",
        "\n",
        "        # Save cache for future use\n",
        "        if self.cache_density:\n",
        "            np.save(cache_path, density_map)\n",
        "\n",
        "        return density_map"
      ],
      "metadata": {
        "id": "XbzD0qxfvvgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model Architecture"
      ],
      "metadata": {
        "id": "wVz7O1GcvwO2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0PPFIATrvyqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data Loading and Training Setup"
      ],
      "metadata": {
        "id": "GItag3HPvzEs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJQUuqlXv3ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Model Training"
      ],
      "metadata": {
        "id": "4T7K-Z_Hv4jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "training_losses = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    for images, density_maps in train_loader:\n",
        "        images = images.to(device)\n",
        "        density_maps = density_maps.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        pred_density_maps = model(images)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(pred_density_maps, density_maps)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    training_losses.append(avg_loss)\n",
        "\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}')\n",
        "\n",
        "print(\"Training completed!\")\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(training_losses)\n",
        "plt.title('Training Loss Over Time')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H7lH3syzv532"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Model Evaluation"
      ],
      "metadata": {
        "id": "KxxdkV5Vv6ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper functions for model evaluation\n",
        "def predict_count(\n",
        "    model: torch.nn.Module,\n",
        "    image_path: str,\n",
        "    device: torch.device,\n",
        "    img_size: int = 224\n",
        ") -> Tuple[np.ndarray, float, np.ndarray]:\n",
        "    model.eval()\n",
        "\n",
        "    # Load and preprocess image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    resized_image = cv2.resize(image, (img_size, img_size))\n",
        "    input_tensor = torch.from_numpy(resized_image).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_density_map = model(input_tensor)\n",
        "\n",
        "    # The predicted count is the sum of the density map\n",
        "    predicted_count = pred_density_map.sum().item()\n",
        "\n",
        "    return image, predicted_count, pred_density_map.squeeze().cpu().numpy()\n",
        "\n",
        "def get_ground_truth_count(image_name: str, label_dir: str) -> int:\n",
        "    label_file = image_name.replace('.jpg', '.json')\n",
        "    label_path = os.path.join(label_dir, label_file)\n",
        "    if not os.path.exists(label_path):\n",
        "        # For test set, we might not have labels. We'll use train labels for MAE calculation.\n",
        "        return 0\n",
        "    with open(label_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data['human_num']\n",
        "\n",
        "def visualize_detections(\n",
        "    original_image: np.ndarray,\n",
        "    pred_map: np.ndarray,\n",
        "    pred_count: float,\n",
        "    true_count: int,\n",
        "    img_name: str,\n",
        "    downscale_factor: int = 16,\n",
        "    threshold_scale: float = 2.0\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Finds peaks in the density map and draws circles on the original image.\n",
        "    \"\"\"\n",
        "    # Find local maxima in the density map\n",
        "    footprint = np.ones((3, 3))\n",
        "    local_max = maximum_filter(pred_map, footprint=footprint) == pred_map\n",
        "\n",
        "    # Apply a threshold to filter out weak peaks\n",
        "    threshold = pred_map.mean() * threshold_scale\n",
        "    peaks = (pred_map > threshold) & local_max\n",
        "\n",
        "    # Get coordinates of the peaks\n",
        "    peak_coords = np.argwhere(peaks) # (row, col) format\n",
        "\n",
        "    # --- Visualization ---\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Draw circles on the original image\n",
        "    img_with_circles = original_image.copy()\n",
        "    orig_h, orig_w = img_with_circles.shape[:2]\n",
        "\n",
        "    for y_map, x_map in peak_coords:\n",
        "        # Scale coordinates from map size back to original image size\n",
        "        x_orig = int((x_map + 0.5) * downscale_factor * (orig_w / 224))\n",
        "        y_orig = int((y_map + 0.5) * downscale_factor * (orig_h / 224))\n",
        "\n",
        "        # Draw a red circle\n",
        "        cv2.circle(img_with_circles, (x_orig, y_orig), radius=15, color=(255, 0, 0), thickness=3)\n",
        "\n",
        "    plt.imshow(img_with_circles)\n",
        "    plt.title(f'Detections for: {img_name}\\nPredicted Count: {pred_count:.2f} | Ground Truth: {true_count}', fontsize=14)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "efirp2bhv724"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Evaluating model\n",
        "print(\"Evaluating model on training images (to check learning)...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "evaluation_results = []\n",
        "sample_images_for_eval = train_dataset.image_files[:30]\n",
        "\n",
        "for img_name in sample_images_for_eval:\n",
        "    img_path = os.path.join(TRAIN_IMG_DIR, img_name)\n",
        "\n",
        "    # Get ground truth\n",
        "    true_count = get_ground_truth_count(img_name, TRAIN_LBL_DIR)\n",
        "\n",
        "    # Get prediction\n",
        "    original_image, pred_count, pred_map = predict_count(model, img_path, device)\n",
        "\n",
        "    evaluation_results.append({\n",
        "        'image_name': img_name,\n",
        "        'true_count': true_count,\n",
        "        'pred_count': pred_count\n",
        "    })\n",
        "\n",
        "    # Visualize first 3 images\n",
        "    if len(evaluation_results) <= 3:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "        ax1.imshow(original_image)\n",
        "        ax1.set_title(f'Original Image: {img_name}')\n",
        "        ax1.axis('off')\n",
        "\n",
        "        im = ax2.imshow(pred_map, cmap='jet')\n",
        "        ax2.set_title(f'Predicted Density Map (Count: {pred_count:.2f})\\nGround Truth: {true_count}')\n",
        "        ax2.axis('off')\n",
        "        fig.colorbar(im, ax=ax2)\n",
        "        plt.show()\n",
        "\n",
        "# Calculate and display MAE\n",
        "eval_df = pd.DataFrame(evaluation_results)\n",
        "mae = (eval_df['pred_count'] - eval_df['true_count']).abs().mean()\n",
        "\n",
        "print(\"\\nEvaluation Results on Training Sample:\")\n",
        "print(eval_df)\n",
        "print(f\"\\nMean Absolute Error (MAE): {mae:.4f}\")"
      ],
      "metadata": {
        "id": "VYYgmUUAxiTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Final Submission Generation"
      ],
      "metadata": {
        "id": "DB753OrNv8zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generating submission file for the test set...\")\n",
        "\n",
        "test_images = sorted(\n",
        "    [f for f in os.listdir(TEST_IMG_DIR) if f.endswith('.jpg')],\n",
        "    key=lambda x: int(os.path.splitext(x)[0])\n",
        ")\n",
        "submission_data = []\n",
        "\n",
        "for img_name in test_images:\n",
        "    img_path = os.path.join(TEST_IMG_DIR, img_name)\n",
        "    _, pred_count, _ = predict_count(model, img_path, device)\n",
        "\n",
        "    submission_data.append({\n",
        "        'image_id': img_name,\n",
        "        'predicted_count': int(round(pred_count))\n",
        "    })\n",
        "\n",
        "submission_df = pd.DataFrame(submission_data)\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully.\")\n",
        "print(\"\\nFirst 5 rows of submission:\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "id": "JTZUc7KAv_o6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}