{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1eed96",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/FarrelAD/Hology-8-2025-Data-Mining-PRIVATE/blob/dev%2Ffarrel/notebooks/farrel/nb_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f770653",
   "metadata": {},
   "source": [
    "# Density FCN for Crowd Counting\n",
    "\n",
    "This notebook implements a Density Fully Convolutional Network for crowd counting tasks.\n",
    "\n",
    "**Features:**\n",
    "- Custom FCN architecture with backbone feature extractor\n",
    "- Density map generation with Gaussian filtering\n",
    "- Data augmentation and preprocessing\n",
    "- Caching mechanism for density maps\n",
    "- Model evaluation and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672fe9f5",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a270b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries and Setup\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter, maximum_filter\n",
    "from typing import Optional, Tuple, Dict, Any, Union, List\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "\n",
    "# Detect environment\n",
    "def detect_environment() -> str:\n",
    "    \"\"\"Detect if running in Colab, Kaggle, or local environment\"\"\"\n",
    "    if 'google.colab' in sys.modules:\n",
    "        return 'colab'\n",
    "    elif 'kaggle_secrets' in sys.modules or os.environ.get('KAGGLE_KERNEL_RUN_TYPE'):\n",
    "        return 'kaggle'\n",
    "    else:\n",
    "        return 'local'\n",
    "\n",
    "ENV = detect_environment()\n",
    "print(f\"üîç Detected environment: {ENV.upper()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üîß Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d49dd2",
   "metadata": {},
   "source": [
    "# Dataset Download and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25265cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment-specific dataset setup\n",
    "def setup_dataset_paths(env: str) -> dict[str, str]:\n",
    "    \"\"\"Setup dataset paths based on environment\"\"\"\n",
    "    \n",
    "    if env == 'colab':\n",
    "        # Google Colab paths\n",
    "        dataset_name = \"penyisihan-hology-8-0-2025-data-mining\"\n",
    "        drive_path = \"/content/drive/MyDrive/PROJECTS/Cognivio/Percobaan Hology 8 2025/dataset\"\n",
    "        local_path = \"/content/dataset\"\n",
    "        \n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        \n",
    "        # Setup Kaggle credentials\n",
    "        if not os.path.exists(\"/root/.kaggle/kaggle.json\"):\n",
    "            print(\"üì• Setting up Kaggle credentials...\")\n",
    "            from google.colab import files\n",
    "            uploaded = files.upload()\n",
    "            \n",
    "            for fn in uploaded.keys():\n",
    "                print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')\n",
    "            \n",
    "            !mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "        \n",
    "        # Download and setup dataset\n",
    "        if not os.path.exists(local_path):\n",
    "            print(\"üì• Setting up dataset in Colab...\")\n",
    "            \n",
    "            # Create directories\n",
    "            os.makedirs(drive_path, exist_ok=True)\n",
    "            \n",
    "            zip_path = f\"/content/{dataset_name}.zip\"\n",
    "            \n",
    "            # Download if not exists\n",
    "            if not os.path.exists(zip_path):\n",
    "                print(\"Dataset not found locally, downloading...\")\n",
    "                !pip install -q kaggle\n",
    "                !kaggle competitions download -c {dataset_name} -p /content\n",
    "            else:\n",
    "                print(\"Dataset already exists, skipping download.\")\n",
    "            \n",
    "            # Extract to Google Drive (for backup)\n",
    "            if not os.listdir(drive_path):\n",
    "                print(\"Extracting dataset to Google Drive...\")\n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(drive_path)\n",
    "                print(f\"Dataset extracted to: {drive_path}\")\n",
    "            else:\n",
    "                print(f\"Dataset already extracted at: {drive_path}\")\n",
    "            \n",
    "            # Copy to local storage for faster access\n",
    "            print(\"Copying dataset to Colab local storage (/content)...\")\n",
    "            !cp -r \"{drive_path}\" \"{local_path}\"\n",
    "            print(f\"‚úÖ Dataset copied to {local_path}\")\n",
    "        \n",
    "        return {\n",
    "            'img_dir': f\"{local_path}/train/images\",\n",
    "            'label_dir': f\"{local_path}/train/labels\",\n",
    "            'test_dir': f\"{local_path}/test/images\",\n",
    "            'save_dir': \"/content/drive/MyDrive/PROJECTS/Cognivio/models\"\n",
    "        }\n",
    "    \n",
    "    elif env == 'kaggle':\n",
    "        # Kaggle paths\n",
    "        return {\n",
    "            'img_dir': \"/kaggle/input/penyisihan-hology-8-0-2025-data-mining/train/images\",\n",
    "            'label_dir': \"/kaggle/input/penyisihan-hology-8-0-2025-data-mining/train/labels\",\n",
    "            'test_dir': \"/kaggle/input/penyisihan-hology-8-0-2025-data-mining/test/images\",\n",
    "            'save_dir': \"/kaggle/working\"\n",
    "        }\n",
    "    \n",
    "    else:  # local\n",
    "        # Local paths - modify these for your setup\n",
    "        base_path = \"../../data\"  # Change this to your local dataset path\n",
    "        return {\n",
    "            'img_dir': f\"{base_path}/train/images\",\n",
    "            'label_dir': f\"{base_path}/train/labels\",\n",
    "            'test_dir': f\"{base_path}/test/images\",\n",
    "            'save_dir': \"models\"\n",
    "        }\n",
    "\n",
    "# Setup paths\n",
    "paths = setup_dataset_paths(ENV)\n",
    "print(f\"üìÅ Dataset paths configured for {ENV}:\")\n",
    "for key, path in paths.items():\n",
    "    exists = \"‚úÖ\" if os.path.exists(path) else \"‚ö†Ô∏è\"\n",
    "    print(f\"   {key}: {path} {exists}\")\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(paths['save_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf601d",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "config = {\n",
    "    # Data paths\n",
    "    'img_dir': paths['img_dir'],\n",
    "    'label_dir': paths['label_dir'],\n",
    "    'test_dir': paths['test_dir'],\n",
    "    'save_dir': paths['save_dir'],\n",
    "    \n",
    "    # Model parameters\n",
    "    'img_size': 224,\n",
    "    'downscale_factor': 16,\n",
    "    'sigma': 4.0,\n",
    "    \n",
    "    # Training parameters\n",
    "    'batch_size': 4,\n",
    "    'epochs': 100,\n",
    "    'lr': 0.0001,\n",
    "    'max_samples': None,  # Use all available samples\n",
    "    \n",
    "    # Optimization\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True,\n",
    "    \n",
    "    # Data processing\n",
    "    'cache_density': True,\n",
    "    'return_meta': False,\n",
    "    \n",
    "    # Model saving\n",
    "    'save_path': os.path.join(paths['save_dir'], 'density_fcn_model.pth'),\n",
    "}\n",
    "\n",
    "print(\"üìã Configuration loaded:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"üîß Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc8514",
   "metadata": {},
   "source": [
    "# Dataset Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrowdCountingDataset(Dataset):\n",
    "    \"\"\"Custom dataset for crowd counting with density map generation.\n",
    "    \n",
    "    Supports caching of density maps for faster training and various\n",
    "    data augmentation options.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        image_dir: str,\n",
    "        label_dir: str,\n",
    "        max_samples: Optional[int] = None,\n",
    "        img_size: int = 224,\n",
    "        downscale_factor: int = 16,\n",
    "        sigma: float = 4.0,\n",
    "        transform: Optional[Any] = None,\n",
    "        return_meta: bool = False,\n",
    "        cache_density: bool = True,\n",
    "    ) -> None:\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_size = img_size\n",
    "        self.downscale_factor = downscale_factor\n",
    "        self.sigma = sigma\n",
    "        self.transform = transform\n",
    "        self.return_meta = return_meta\n",
    "        self.cache_density = cache_density\n",
    "\n",
    "        # Collect image files\n",
    "        all_images = sorted([f for f in os.listdir(image_dir) if f.endswith(\".jpg\")])\n",
    "        if max_samples:\n",
    "            self.image_files = all_images[:max_samples]\n",
    "        else:\n",
    "            self.image_files = all_images\n",
    "\n",
    "        # Pre-load label jsons into memory (fast lookup)\n",
    "        self.labels = self._load_labels()\n",
    "\n",
    "        print(f\"üì¶ Using {len(self.image_files)} images for dataset.\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        idx: int\n",
    "    ) -> Union[Tuple[torch.Tensor, torch.Tensor], Dict[str, Any]]:\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "\n",
    "        # ---- Load and resize image ----\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        orig_h, orig_w = image.shape[:2]\n",
    "        image = cv2.resize(image, (self.img_size, self.img_size))\n",
    "        image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image_tensor)\n",
    "\n",
    "        # ---- Get density map (cached or computed) ----\n",
    "        density_map = self._get_density_map(img_name, orig_w, orig_h)\n",
    "        density_map_tensor = torch.from_numpy(density_map).unsqueeze(0)\n",
    "\n",
    "        # Compute crowd count\n",
    "        count = float(density_map_tensor.sum())\n",
    "\n",
    "        if self.return_meta:\n",
    "            return {\n",
    "                \"image\": image_tensor,\n",
    "                \"density\": density_map_tensor,\n",
    "                \"count\": count,\n",
    "                \"name\": img_name,\n",
    "                \"orig_size\": (orig_h, orig_w),\n",
    "            }\n",
    "        else:\n",
    "            return image_tensor, density_map_tensor\n",
    "\n",
    "    def _load_labels(\n",
    "        self\n",
    "    ) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"Load labels from JSON files into memory.\"\"\"\n",
    "        labels = {}\n",
    "        for img_file in self.image_files:\n",
    "            label_file = img_file.replace(\".jpg\", \".json\")\n",
    "            label_path = os.path.join(self.label_dir, label_file)\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, \"r\") as f:\n",
    "                    labels[img_file] = json.load(f)\n",
    "        return labels\n",
    "\n",
    "    def _get_density_map(\n",
    "        self, \n",
    "        img_name: str, \n",
    "        orig_w: int, \n",
    "        orig_h: int\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Generate or load precomputed density map.\"\"\"\n",
    "        output_size = self.img_size // self.downscale_factor\n",
    "        cache_path = os.path.join(self.label_dir, img_name.replace(\".jpg\", \".npy\"))\n",
    "\n",
    "        # If cached density exists, just load\n",
    "        if self.cache_density and os.path.exists(cache_path):\n",
    "            return np.load(cache_path)\n",
    "\n",
    "        # Otherwise, compute density map\n",
    "        density_map = np.zeros((output_size, output_size), dtype=np.float32)\n",
    "        label_data = self.labels.get(img_name)\n",
    "\n",
    "        if label_data and label_data.get(\"human_num\", 0) > 0:\n",
    "            raw_points = label_data[\"points\"]\n",
    "\n",
    "            points = np.array([[p[\"x\"], p[\"y\"]] for p in raw_points], dtype=np.float32)\n",
    "\n",
    "            for x, y in points:\n",
    "                scaled_x = (x / orig_w) * output_size\n",
    "                scaled_y = (y / orig_h) * output_size\n",
    "                ix, iy = int(scaled_x), int(scaled_y)\n",
    "                if 0 <= ix < output_size and 0 <= iy < output_size:\n",
    "                    density_map[iy, ix] += 1.0\n",
    "\n",
    "        # Apply Gaussian filter\n",
    "        density_map = gaussian_filter(density_map, sigma=self.sigma / self.downscale_factor)\n",
    "\n",
    "        # Save cache for future use\n",
    "        if self.cache_density:\n",
    "            np.save(cache_path, density_map)\n",
    "\n",
    "        return density_map\n",
    "\n",
    "print(\"‚úÖ CrowdCountingDataset class implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01d7c9",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b57ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensityFCN(nn.Module):\n",
    "    \"\"\"Fully Convolutional Network for density estimation.\n",
    "    \n",
    "    Features a backbone feature extractor followed by a density prediction head.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super(DensityFCN, self).__init__()\n",
    "        # Backbone: Feature extractor\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 224 -> 112\n",
    "            nn.Conv2d(16, 32, 3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 112 -> 56\n",
    "            nn.Conv2d(32, 64, 3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 56 -> 28\n",
    "            nn.Conv2d(64, 128, 3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 28 -> 14\n",
    "        )\n",
    "        # Head: Density map predictor\n",
    "        self.head = nn.Conv2d(128, 1, 1) # 1x1 conv to produce 1-channel map\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "print(\"‚úÖ DensityFCN model architecture implemented!\")\n",
    "\n",
    "# Test model instantiation\n",
    "model_test = DensityFCN().to(device)\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model_test.parameters()):,}\")\n",
    "print(\"Model architecture:\")\n",
    "print(model_test)\n",
    "\n",
    "del model_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adbb819",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a678fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data directories exist\n",
    "img_dir = config['img_dir']\n",
    "label_dir = config['label_dir']\n",
    "\n",
    "print(f\"üîç Checking data directories...\")\n",
    "print(f\"   Images: {img_dir} -> {'‚úÖ Exists' if os.path.exists(img_dir) else '‚ùå Not found'}\")\n",
    "print(f\"   Labels: {label_dir} -> {'‚úÖ Exists' if os.path.exists(label_dir) else '‚ùå Not found'}\")\n",
    "\n",
    "if not os.path.exists(img_dir):\n",
    "    raise Exception(\"‚ùå Image directory not found. Please check the path and try again.\")\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = CrowdCountingDataset(\n",
    "    image_dir=config['img_dir'],\n",
    "    label_dir=config['label_dir'],\n",
    "    img_size=config['img_size'],\n",
    "    downscale_factor=config['downscale_factor'],\n",
    "    sigma=config['sigma'],\n",
    "    cache_density=config['cache_density'],\n",
    "    max_samples=config['max_samples'],\n",
    ")\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=config['pin_memory'],\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Data loader created!\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fcb9a8",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0621b738",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and training components\n",
    "print(\"üèóÔ∏è  Initializing model and training components...\")\n",
    "\n",
    "# Create model\n",
    "model = DensityFCN().to(device)\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss() # Pixel-wise MSE for density map regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "\n",
    "print(\"‚úÖ Setup complete! Starting training...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6664028",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeab3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Training Loop\n",
    "training_losses = []\n",
    "\n",
    "print(\"üöÄ Starting training...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (images, density_maps) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        density_maps = density_maps.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        pred_density_maps = model(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(pred_density_maps, density_maps)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    training_losses.append(avg_loss)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        print(f'üìà Epoch {epoch+1}/{config[\"epochs\"]}, Loss: {avg_loss:.6f}')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16731626",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(training_losses, 'b-', linewidth=2)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà Training Statistics:\")\n",
    "print(f\"   Final Loss: {training_losses[-1]:.6f}\")\n",
    "print(f\"   Total Epochs: {len(training_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4bbf4b",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_count(\n",
    "    model: torch.nn.Module,\n",
    "    image_path: str,\n",
    "    device: torch.device,\n",
    "    img_size: int = 224\n",
    ") -> Tuple[np.ndarray, float, np.ndarray]:\n",
    "    \"\"\"Predict crowd count for a single image.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Load and preprocess image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    resized_image = cv2.resize(image, (img_size, img_size))\n",
    "    input_tensor = torch.from_numpy(resized_image).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_density_map = model(input_tensor)\n",
    "\n",
    "    # The predicted count is the sum of the density map\n",
    "    predicted_count = pred_density_map.sum().item()\n",
    "\n",
    "    return image, predicted_count, pred_density_map.squeeze().cpu().numpy()\n",
    "\n",
    "def get_ground_truth_count(\n",
    "    image_name: str, \n",
    "    label_dir: str\n",
    ") -> int:\n",
    "    \"\"\"Get ground truth count from JSON label file.\"\"\"\n",
    "    label_file = image_name.replace('.jpg', '.json')\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "    if not os.path.exists(label_path):\n",
    "        # For test set, we might not have labels. We'll use train labels for MAE calculation.\n",
    "        return 0\n",
    "    with open(label_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['human_num']\n",
    "\n",
    "def visualize_detections(\n",
    "    original_image: np.ndarray,\n",
    "    pred_map: np.ndarray,\n",
    "    pred_count: float,\n",
    "    true_count: int,\n",
    "    img_name: str,\n",
    "    downscale_factor: int = 16,\n",
    "    threshold_scale: float = 2.0\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Finds peaks in the density map and draws circles on the original image.\n",
    "    \"\"\"\n",
    "    # Find local maxima in the density map\n",
    "    footprint = np.ones((3, 3))\n",
    "    local_max = maximum_filter(pred_map, footprint=footprint) == pred_map\n",
    "\n",
    "    # Apply a threshold to filter out weak peaks\n",
    "    threshold = pred_map.mean() * threshold_scale\n",
    "    peaks = (pred_map > threshold) & local_max\n",
    "\n",
    "    # Get coordinates of the peaks\n",
    "    peak_coords = np.argwhere(peaks) # (row, col) format\n",
    "\n",
    "    # --- Visualization ---\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Draw circles on the original image\n",
    "    img_with_circles = original_image.copy()\n",
    "    orig_h, orig_w = img_with_circles.shape[:2]\n",
    "\n",
    "    for y_map, x_map in peak_coords:\n",
    "        # Scale coordinates from map size back to original image size\n",
    "        x_orig = int((x_map + 0.5) * downscale_factor * (orig_w / 224))\n",
    "        y_orig = int((y_map + 0.5) * downscale_factor * (orig_h / 224))\n",
    "\n",
    "        # Draw a red circle\n",
    "        cv2.circle(img_with_circles, (x_orig, y_orig), radius=15, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "    plt.imshow(img_with_circles)\n",
    "    plt.title(f'Detections for: {img_name}\\nPredicted Count: {pred_count:.2f} | Ground Truth: {true_count}', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Evaluation functions implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f142a12",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Evaluating model on training images (to check learning)...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "evaluation_results = []\n",
    "sample_images_for_eval = train_dataset.image_files[:10] # Use first 10 training images for eval\n",
    "\n",
    "for img_name in sample_images_for_eval:\n",
    "    img_path = os.path.join(config['img_dir'], img_name)\n",
    "\n",
    "    # Get ground truth\n",
    "    true_count = get_ground_truth_count(img_name, config['label_dir'])\n",
    "\n",
    "    # Get prediction\n",
    "    original_image, pred_count, pred_map = predict_count(model, img_path, device, config['img_size'])\n",
    "\n",
    "    evaluation_results.append({\n",
    "        'image_name': img_name,\n",
    "        'true_count': true_count,\n",
    "        'pred_count': pred_count\n",
    "    })\n",
    "\n",
    "    # Visualize first 3 images\n",
    "    if len(evaluation_results) <= 3:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(original_image)\n",
    "        ax1.set_title(f'Original Image: {img_name}')\n",
    "        ax1.axis('off')\n",
    "\n",
    "        im = ax2.imshow(pred_map, cmap='jet')\n",
    "        ax2.set_title(f'Predicted Density Map (Count: {pred_count:.2f})\\nGround Truth: {true_count}')\n",
    "        ax2.axis('off')\n",
    "        fig.colorbar(im, ax=ax2)\n",
    "        plt.show()\n",
    "\n",
    "# Calculate and display MAE\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "mae = (eval_df['pred_count'] - eval_df['true_count']).abs().mean()\n",
    "\n",
    "print(\"\\nüìä Evaluation Results on Training Sample:\")\n",
    "print(eval_df)\n",
    "print(f\"\\nüìà Mean Absolute Error (MAE): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a3240",
   "metadata": {},
   "source": [
    "# Test Prediction and Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset for inference\n",
    "class TestDataset(Dataset):\n",
    "    \"\"\"Simple test dataset for inference.\"\"\"\n",
    "    \n",
    "    def __init__(self, img_dir: str, img_size: int = 224) -> None:\n",
    "        self.img_paths: List[str] = sorted(\n",
    "            [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.jpg')],\n",
    "            key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
    "        )\n",
    "        self.img_size: int = img_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[str, np.ndarray]:\n",
    "        img_path: str = self.img_paths[index]\n",
    "        image_name: str = os.path.basename(img_path)\n",
    "        return image_name, img_path\n",
    "\n",
    "# Generate submission\n",
    "print(\"üìù Generating submission file for the test set...\")\n",
    "\n",
    "test_images = sorted(\n",
    "    [f for f in os.listdir(config['test_dir']) if f.endswith('.jpg')],\n",
    "    key=lambda x: int(os.path.splitext(x)[0])\n",
    ")\n",
    "submission_data = []\n",
    "\n",
    "for img_name in test_images:\n",
    "    img_path = os.path.join(config['test_dir'], img_name)\n",
    "    _, pred_count, _ = predict_count(model, img_path, device, config['img_size'])\n",
    "\n",
    "    submission_data.append({\n",
    "        'image_id': img_name,\n",
    "        'predicted_count': int(round(pred_count))\n",
    "    })\n",
    "\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "submission_csv_path = os.path.join(config['save_dir'], 'submission.csv')\n",
    "submission_df.to_csv(submission_csv_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Submission saved to {submission_csv_path}\")\n",
    "print(\"\\nüìã Sample submission:\")\n",
    "submission_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6f76f",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fc0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saving for Competition Submission\n",
    "print(\"üíæ Saving trained model...\")\n",
    "\n",
    "# Save complete model (architecture + weights)\n",
    "model_complete_path = os.path.join(config['save_dir'], 'density_fcn_model_complete.pth')\n",
    "torch.save(model, model_complete_path)\n",
    "print(f\"‚úÖ Complete model saved to: {model_complete_path}\")\n",
    "\n",
    "# Save model state dict only\n",
    "model_weights_path = os.path.join(config['save_dir'], 'density_fcn_model_weights.pth')\n",
    "torch.save(model.state_dict(), model_weights_path)\n",
    "print(f\"‚úÖ Model weights saved to: {model_weights_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Training and evaluation complete!\")\n",
    "print(f\"üéØ Model saved at: {config['save_dir']}\")\n",
    "print(\"üìä Evaluation results and visualizations have been generated above.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
