{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e23ad361",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/FarrelAD/Hology-8-2025-Data-Mining-PRIVATE/blob/main/notebooks/vidi/nb_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515af881",
   "metadata": {},
   "source": [
    "# Hybrid Crowd Counting Model - SimpleCountingNet\n",
    "\n",
    "This notebook implements a hybrid crowd counting model combining density map prediction and direct count regression.\n",
    "\n",
    "**Features:**\n",
    "- Dual-head architecture with density and count outputs\n",
    "- Advanced data augmentation with Albumentations\n",
    "- Hybrid loss function combining MSE and L1 losses\n",
    "- Comprehensive evaluation and visualization\n",
    "- Early stopping and model checkpointing\n",
    "- Test set prediction and submission generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c617b",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries and Setup\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "\n",
    "# Detect environment\n",
    "def detect_environment():\n",
    "    \"\"\"Detect if running in Colab, Kaggle, or local environment\"\"\"\n",
    "    if 'google.colab' in sys.modules:\n",
    "        return 'colab'\n",
    "    elif 'kaggle_secrets' in sys.modules or os.environ.get('KAGGLE_KERNEL_RUN_TYPE'):\n",
    "        return 'kaggle'\n",
    "    else:\n",
    "        return 'local'\n",
    "\n",
    "ENV = detect_environment()\n",
    "print(f\"üîç Detected environment: {ENV.upper()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üîß Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b255b",
   "metadata": {},
   "source": [
    "# Dataset Download and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment-specific dataset setup\n",
    "def setup_dataset_paths(env: str) -> Dict[str, str]:\n",
    "    \"\"\"Setup dataset paths based on environment\"\"\"\n",
    "    \n",
    "    if env == 'colab':\n",
    "        # Google Colab paths\n",
    "        dataset_name = \"penyisihan-hology-8-0-2025-data-mining\"\n",
    "        drive_path = \"/content/drive/MyDrive/PROJECTS/Cognivio/Percobaan Hology 8 2025/dataset\"\n",
    "        local_path = \"../../data\"\n",
    "        \n",
    "        # Mount Google Drive\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        \n",
    "        # Setup Kaggle credentials\n",
    "        if not os.path.exists(\"/root/.kaggle/kaggle.json\"):\n",
    "            print(\"üì• Setting up Kaggle credentials...\")\n",
    "            from google.colab import files\n",
    "            uploaded = files.upload()\n",
    "            \n",
    "            for fn in uploaded.keys():\n",
    "                print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')\n",
    "            \n",
    "            !mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
    "        \n",
    "        # Download and setup dataset\n",
    "        if not os.path.exists(local_path):\n",
    "            print(\"üì• Setting up dataset in Colab...\")\n",
    "            \n",
    "            zip_path = f\"/content/{dataset_name}.zip\"\n",
    "            \n",
    "            # Download if not exists\n",
    "            if not os.path.exists(zip_path):\n",
    "                print(\"Dataset not found locally, downloading...\")\n",
    "                !pip install -q kaggle\n",
    "                !kaggle competitions download -c {dataset_name} -p /content\n",
    "            else:\n",
    "                print(\"Dataset already exists, skipping download.\")\n",
    "            \n",
    "            # Extract to Google Drive (for backup)\n",
    "            os.makedirs(drive_path, exist_ok=True)\n",
    "            if not os.listdir(drive_path):\n",
    "                print(\"Extracting dataset to Google Drive...\")\n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(drive_path)\n",
    "                print(f\"Dataset extracted to: {drive_path}\")\n",
    "            else:\n",
    "                print(f\"Dataset already extracted at: {drive_path}\")\n",
    "            \n",
    "            # Copy to local storage for faster access\n",
    "            print(\"Copying dataset to Colab local storage (/content)...\")\n",
    "            !cp -r \"{drive_path}\" \"{local_path}\"\n",
    "            print(f\"‚úÖ Dataset copied to {local_path}\")\n",
    "        \n",
    "        return {\n",
    "            'img_dir': f\"{local_path}/train/images\",\n",
    "            'label_dir': f\"{local_path}/train/labels\",\n",
    "            'test_dir': f\"{local_path}/test/images\",\n",
    "            'save_dir': \"/content/drive/MyDrive/PROJECTS/Cognivio/models\"\n",
    "        }\n",
    "    \n",
    "    elif env == 'kaggle':\n",
    "        # Kaggle paths\n",
    "        return {\n",
    "            'img_dir': \"/kaggle/input/penyisihan-hology-8-0-2025-data-mining/train/images\",\n",
    "            'label_dir': \"/kaggle/input/penyisihan-hology-8-0-2025-data-mining/train/labels\",\n",
    "            'test_dir': \"/kaggle/input/penyisihan-hology-8-0-2025-data-mining/test/images\",\n",
    "            'save_dir': \"/kaggle/working\"\n",
    "        }\n",
    "    \n",
    "    else:  # local\n",
    "        # Local paths\n",
    "        base_path = \"../../data\"\n",
    "        return {\n",
    "            'img_dir': f\"{base_path}/train/images\",\n",
    "            'label_dir': f\"{base_path}/train/labels\",\n",
    "            'test_dir': f\"{base_path}/test/images\",\n",
    "            'save_dir': \"models\"\n",
    "        }\n",
    "\n",
    "# Setup paths\n",
    "paths = setup_dataset_paths(ENV)\n",
    "print(f\"üìÅ Dataset paths configured for {ENV}:\")\n",
    "for key, path in paths.items():\n",
    "    exists = \"‚úÖ\" if os.path.exists(path) else \"‚ö†Ô∏è\"\n",
    "    print(f\"   {key}: {path} {exists}\")\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(paths['save_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54740bbf",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "config = {\n",
    "    # Data paths\n",
    "    'img_dir': paths['img_dir'],\n",
    "    'label_dir': paths['label_dir'],\n",
    "    'test_dir': paths['test_dir'],\n",
    "    'save_dir': paths['save_dir'],\n",
    "    \n",
    "    # Model parameters\n",
    "    'batch_size': 8,\n",
    "    'epochs': 50,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    \n",
    "    # Training parameters\n",
    "    'num_workers': 2,\n",
    "    'pin_memory': True,\n",
    "    'early_stop_patience': 10,\n",
    "    \n",
    "    # Loss function weights\n",
    "    'density_weight': 1.0,\n",
    "    'count_weight': 10.0,\n",
    "    \n",
    "    # Model saving\n",
    "    'best_model_path': os.path.join(paths['save_dir'], 'best_hybrid_model.pth'),\n",
    "    'submission_path': os.path.join(paths['save_dir'], 'hybrid_submission.csv'),\n",
    "    'seed': 31\n",
    "}\n",
    "\n",
    "print(\"üìã Configuration loaded:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "    \n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed: int = 31) -> None:\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(config['seed'])\n",
    "print(f\"üé≤ Random seed set to {config['seed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e08be1",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üîç Analyzing dataset...\")\n",
    "\n",
    "def load_crowd_counts(label_dir: str) -> Dict[str, int]:\n",
    "    \"\"\"Load crowd counts from JSON label files.\"\"\"\n",
    "    crowd_counts = {}\n",
    "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.json')]\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        img_name = label_file.replace('.json', '.jpg')\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            crowd_counts[img_name] = data.get('human_num', 0)\n",
    "    \n",
    "    return crowd_counts\n",
    "\n",
    "def create_density_map(\n",
    "    annotations: List[Tuple[int, int]],\n",
    "    img_height: int,\n",
    "    img_width: int,\n",
    "    sigma: float = 15.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Create density map from point annotations using Gaussian kernels.\"\"\"\n",
    "    density_map = np.zeros((img_height, img_width), dtype=np.float32)\n",
    "    \n",
    "    for x, y in annotations:\n",
    "        if 0 <= x < img_width and 0 <= y < img_height:\n",
    "            density_map[y, x] = 1.0\n",
    "    \n",
    "    # Apply Gaussian filter to create density map\n",
    "    density_map = scipy.ndimage.gaussian_filter(density_map, sigma=sigma)\n",
    "    \n",
    "    return density_map\n",
    "\n",
    "# Load crowd counts\n",
    "crowd_counts = load_crowd_counts(config['label_dir'])\n",
    "print(f\"üìä Loaded {len(crowd_counts)} crowd count labels\")\n",
    "\n",
    "# Analyze crowd count distribution\n",
    "crowd_values = np.array(list(crowd_counts.values()))\n",
    "print(f\"\\nüìà Crowd count statistics:\")\n",
    "print(f\"Mean: {crowd_values.mean():.2f}\")\n",
    "print(f\"Std: {crowd_values.std():.2f}\")\n",
    "print(f\"Min: {crowd_values.min()}\")\n",
    "print(f\"Max: {crowd_values.max()}\")\n",
    "print(f\"Median: {np.median(crowd_values):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14efa078",
   "metadata": {},
   "source": [
    "# Data Augmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31ce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé® Setting up data augmentation...\")\n",
    "\n",
    "# Data augmentation transforms\n",
    "train_transforms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=512),\n",
    "    A.PadIfNeeded(min_height=512, min_width=512, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "    A.RandomResizedCrop(height=512, width=512, size=(512, 512), scale=(0.7, 1.0), ratio=(0.75, 1.33)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.7),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], additional_targets={'density': 'mask'}, is_check_shapes=False)\n",
    "\n",
    "val_transforms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=512),\n",
    "    A.PadIfNeeded(min_height=512, min_width=512, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], additional_targets={'density': 'mask'}, is_check_shapes=False)\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=512),\n",
    "    A.PadIfNeeded(min_height=512, min_width=512, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], is_check_shapes=False)\n",
    "\n",
    "print(\"‚úÖ Data augmentation transforms configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40364fa8",
   "metadata": {},
   "source": [
    "# Dataset Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridCrowdDataset(Dataset):\n",
    "    \"\"\"Dataset for hybrid density + count regression training.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        image_dir: str,\n",
    "        crowd_counts: Dict[str, int],\n",
    "        image_files: List[str],\n",
    "        transform=None,\n",
    "        use_density_maps: bool = True\n",
    "    ) -> None:\n",
    "        self.image_dir = image_dir\n",
    "        self.crowd_counts = crowd_counts\n",
    "        self.image_files = [f for f in image_files if f in crowd_counts]\n",
    "        self.transform = transform\n",
    "        self.use_density_maps = use_density_maps\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        \n",
    "        # Load image (BGR ‚Üí RGB)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Count label\n",
    "        count = self.crowd_counts[img_name]\n",
    "        img_height, img_width = image.shape[:2]\n",
    "        \n",
    "        # Create simple density map (uniform distribution)\n",
    "        target_height = img_height // 4\n",
    "        target_width = img_width // 4\n",
    "        density_map = np.full(\n",
    "            (target_height, target_width),\n",
    "            count / (target_height * target_width),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Apply Albumentations transforms\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            augmented_image = augmented[\"image\"]  # Tensor [C, H, W]\n",
    "        else:\n",
    "            augmented_image = ToTensorV2()(image=image)[\"image\"]\n",
    "        \n",
    "        # Resize density map to match augmented image resolution (quarter size)\n",
    "        aug_img_height, aug_img_width = augmented_image.shape[1:]  # (C, H, W)\n",
    "        target_density_height = aug_img_height // 4\n",
    "        target_density_width = aug_img_width // 4\n",
    "        \n",
    "        density_map_resized = cv2.resize(\n",
    "            density_map,\n",
    "            (target_density_width, target_density_height),\n",
    "            interpolation=cv2.INTER_LINEAR\n",
    "        )\n",
    "        \n",
    "        # Normalize to preserve total count after resize\n",
    "        if density_map_resized.sum() > 0:\n",
    "            density_map_resized *= (count / density_map_resized.sum())\n",
    "        \n",
    "        density_tensor = torch.tensor(density_map_resized, dtype=torch.float32).unsqueeze(0)\n",
    "        count_tensor = torch.tensor(count, dtype=torch.float32)\n",
    "        \n",
    "        if self.use_density_maps:\n",
    "            return augmented_image, density_tensor, count_tensor\n",
    "        else:\n",
    "            return augmented_image, count_tensor\n",
    "\n",
    "print(\"‚úÖ HybridCrowdDataset class implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a0ee3f",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6213d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Preparing datasets...\")\n",
    "\n",
    "# Create train-val split\n",
    "image_files = list(crowd_counts.keys())\n",
    "train_files, val_files = train_test_split(\n",
    "    image_files,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = HybridCrowdDataset(\n",
    "    image_dir=config['img_dir'],\n",
    "    crowd_counts=crowd_counts,\n",
    "    image_files=train_files,\n",
    "    transform=train_transforms\n",
    ")\n",
    "val_dataset = HybridCrowdDataset(\n",
    "    image_dir=config['img_dir'],\n",
    "    crowd_counts=crowd_counts,\n",
    "    image_files=val_files,\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=config['pin_memory']\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=config['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"üì¶ Dataset sizes:\")\n",
    "print(f\"   Training set: {len(train_dataset)} images\")\n",
    "print(f\"   Validation set: {len(val_dataset)} images\")\n",
    "print(f\"üöÄ Data loaders created!\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dae906",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8bb86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCountingNet(nn.Module):\n",
    "    \"\"\"Simple CNN-based crowd counting model with dual outputs.\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super(SimpleCountingNet, self).__init__()\n",
    "        \n",
    "        # Simple CNN backbone\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Density regression head\n",
    "        self.density_head = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Count regression head\n",
    "        self.count_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        true_density_size: Optional[Tuple[int, int]] = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Extract features\n",
    "        features = self.features(x)\n",
    "        \n",
    "        # Density map prediction\n",
    "        density = self.density_head(features)\n",
    "        \n",
    "        # Upsample to match the size of the true density map\n",
    "        if true_density_size is not None:\n",
    "            density = F.interpolate(\n",
    "                density,\n",
    "                size=true_density_size,\n",
    "                mode='bilinear',\n",
    "                align_corners=False\n",
    "            )\n",
    "        else:  # Default upsampling if size is not provided (e.g., for inference)\n",
    "            density = F.interpolate(\n",
    "                density,\n",
    "                scale_factor=8,  # Assuming feature map is 1/8th of original size\n",
    "                mode='bilinear',\n",
    "                align_corners=False\n",
    "            )\n",
    "        \n",
    "        # Count prediction\n",
    "        count = self.count_head(features).squeeze()\n",
    "        \n",
    "        return density, count\n",
    "\n",
    "print(\"‚úÖ SimpleCountingNet model architecture implemented!\")\n",
    "\n",
    "# Test model instantiation\n",
    "model_test = SimpleCountingNet().to(device)\n",
    "total_params = sum(p.numel() for p in model_test.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_test.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"üìä Model parameters:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "del model_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a011589",
   "metadata": {},
   "source": [
    "# Loss Functions and Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30952eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridLoss(nn.Module):\n",
    "    \"\"\"Hybrid loss combining density map MSE and count regression.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        density_weight: float = 1.0,\n",
    "        count_weight: float = 10.0\n",
    "    ) -> None:\n",
    "        super(HybridLoss, self).__init__()\n",
    "        self.density_weight = density_weight\n",
    "        self.count_weight = count_weight\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        pred_density: torch.Tensor,\n",
    "        pred_count: torch.Tensor,\n",
    "        true_density: torch.Tensor,\n",
    "        true_count: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # Density map loss (MSE)\n",
    "        density_loss = self.mse_loss(pred_density, true_density)\n",
    "        \n",
    "        # Count regression loss (L1)\n",
    "        count_loss = self.l1_loss(pred_count, true_count)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = self.density_weight * density_loss + self.count_weight * count_loss\n",
    "        \n",
    "        return total_loss, density_loss, count_loss\n",
    "\n",
    "def train_hybrid_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int = 50,\n",
    "    learning_rate: float = 0.001\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"Train the hybrid model with both density and count supervision.\"\"\"\n",
    "    \n",
    "    criterion = HybridLoss(\n",
    "        density_weight=config['density_weight'],\n",
    "        count_weight=config['count_weight']\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=5\n",
    "    )\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_density_loss': [], 'val_density_loss': [],\n",
    "        'train_count_loss': [], 'val_count_loss': [],\n",
    "        'train_mae': [], 'val_mae': []\n",
    "    }\n",
    "    \n",
    "    best_val_mae = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(\"üöÄ Starting hybrid training...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nüìà Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_density_loss = 0.0\n",
    "        train_count_loss = 0.0\n",
    "        train_mae = 0.0\n",
    "        \n",
    "        for batch_idx, (images, density_maps, counts) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            density_maps = density_maps.to(device)\n",
    "            counts = counts.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_density, pred_count = model(\n",
    "                images, \n",
    "                true_density_size=(density_maps.shape[2], density_maps.shape[3])\n",
    "            )\n",
    "            \n",
    "            # Calculate loss\n",
    "            total_loss, density_loss, count_loss = criterion(\n",
    "                pred_density, pred_count, density_maps, counts\n",
    "            )\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate losses\n",
    "            train_loss += total_loss.item()\n",
    "            train_density_loss += density_loss.item()\n",
    "            train_count_loss += count_loss.item()\n",
    "            train_mae += nn.L1Loss()(pred_count, counts).item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_density_loss = 0.0\n",
    "        val_count_loss = 0.0\n",
    "        val_mae = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, density_maps, counts in val_loader:\n",
    "                images = images.to(device)\n",
    "                density_maps = density_maps.to(device)\n",
    "                counts = counts.to(device)\n",
    "                \n",
    "                pred_density, pred_count = model(\n",
    "                    images,\n",
    "                    true_density_size=(density_maps.shape[2], density_maps.shape[3])\n",
    "                )\n",
    "                total_loss, density_loss, count_loss = criterion(\n",
    "                    pred_density, pred_count, density_maps, counts\n",
    "                )\n",
    "                \n",
    "                val_loss += total_loss.item()\n",
    "                val_density_loss += density_loss.item()\n",
    "                val_count_loss += count_loss.item()\n",
    "                val_mae += nn.L1Loss()(pred_count, counts).item()\n",
    "        \n",
    "        # Calculate averages\n",
    "        train_loss /= len(train_loader)\n",
    "        train_density_loss /= len(train_loader)\n",
    "        train_count_loss /= len(train_loader)\n",
    "        train_mae /= len(train_loader)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_density_loss /= len(val_loader)\n",
    "        val_count_loss /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_mae)\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_density_loss'].append(train_density_loss)\n",
    "        history['val_density_loss'].append(val_density_loss)\n",
    "        history['train_count_loss'].append(train_count_loss)\n",
    "        history['val_count_loss'].append(val_count_loss)\n",
    "        history['train_mae'].append(train_mae)\n",
    "        history['val_mae'].append(val_mae)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f'üìä Loss: {train_loss:.4f}/{val_loss:.4f} | '\n",
    "              f'MAE: {train_mae:.4f}/{val_mae:.4f} | '\n",
    "              f'Count Loss: {train_count_loss:.4f}/{val_count_loss:.4f}')\n",
    "        print(f'üéØ Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_mae < best_val_mae:\n",
    "            best_val_mae = val_mae\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), config['best_model_path'])\n",
    "            print(f\"‚úÖ New best model saved! MAE: {best_val_mae:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"‚è≥ No improvement for {patience_counter} epoch(s)\")\n",
    "        \n",
    "        if patience_counter >= config['early_stop_patience']:\n",
    "            print(f'üõë Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(config['best_model_path']))\n",
    "    print(f\"\\nüéâ Training completed! Best validation MAE: {best_val_mae:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"‚úÖ Loss functions and training setup implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e60de9",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ceb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and training components\n",
    "print(\"üèóÔ∏è  Initializing model and training components...\")\n",
    "\n",
    "# Create model\n",
    "model = SimpleCountingNet().to(device)\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Train the model\n",
    "training_history = train_hybrid_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=config['epochs'],\n",
    "    learning_rate=config['lr']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83fec00",
   "metadata": {},
   "source": [
    "# Evaluation and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88940825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid_model(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    dataset_name: str = \"Dataset\"\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"Comprehensive evaluation of hybrid model.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_pred_counts = []\n",
    "    all_true_counts = []\n",
    "    all_pred_densities = []\n",
    "    all_true_densities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, density_maps, counts in data_loader:\n",
    "            images = images.to(device)\n",
    "            density_maps = density_maps.to(device)\n",
    "            counts = counts.to(device)\n",
    "            \n",
    "            pred_density, pred_count = model(images)\n",
    "            \n",
    "            all_pred_counts.extend(pred_count.cpu().numpy())\n",
    "            all_true_counts.extend(counts.cpu().numpy())\n",
    "            all_pred_densities.extend(pred_density.cpu().numpy())\n",
    "            all_true_densities.extend(density_maps.cpu().numpy())\n",
    "    \n",
    "    pred_counts = np.array(all_pred_counts)\n",
    "    true_counts = np.array(all_true_counts)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(true_counts, pred_counts)\n",
    "    mse = mean_squared_error(true_counts, pred_counts)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Additional metrics\n",
    "    mape = np.mean(np.abs((true_counts - pred_counts) / (true_counts + 1e-8))) * 100\n",
    "    correlation = np.corrcoef(true_counts, pred_counts)[0, 1]\n",
    "    \n",
    "    print(f\"\\nüìä {dataset_name} Evaluation Results:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"MAE (Count):     {mae:.4f}\")\n",
    "    print(f\"MSE (Count):     {mse:.4f}\")\n",
    "    print(f\"RMSE (Count):    {rmse:.4f}\")\n",
    "    print(f\"MAPE (%):        {mape:.2f}\")\n",
    "    print(f\"Correlation:     {correlation:.4f}\")\n",
    "    print(f\"Mean True Count: {np.mean(true_counts):.2f}\")\n",
    "    print(f\"Mean Pred Count: {np.mean(pred_counts):.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape,\n",
    "        'correlation': correlation,\n",
    "        'pred_counts': pred_counts,\n",
    "        'true_counts': true_counts\n",
    "    }\n",
    "\n",
    "# Evaluate on both sets\n",
    "print(\"üéØ Evaluating model performance...\")\n",
    "train_results = evaluate_hybrid_model(model, train_loader, \"Training Set\")\n",
    "val_results = evaluate_hybrid_model(model, val_loader, \"Validation Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2487665f",
   "metadata": {},
   "source": [
    "# Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hybrid_training_history(history: Dict[str, List[float]]) -> None:\n",
    "    \"\"\"Plot training history for hybrid model.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # Total loss\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss', color='red')\n",
    "    axes[0, 0].set_title('Total Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Count loss\n",
    "    axes[0, 1].plot(history['train_count_loss'], label='Train Count Loss', color='blue')\n",
    "    axes[0, 1].plot(history['val_count_loss'], label='Val Count Loss', color='red')\n",
    "    axes[0, 1].set_title('Count Regression Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Density loss\n",
    "    axes[0, 2].plot(history['train_density_loss'], label='Train Density Loss', color='blue')\n",
    "    axes[0, 2].plot(history['val_density_loss'], label='Val Density Loss', color='red')\n",
    "    axes[0, 2].set_title('Density Map Loss')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Loss')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE\n",
    "    axes[1, 0].plot(history['train_mae'], label='Train MAE', color='blue')\n",
    "    axes[1, 0].plot(history['val_mae'], label='Val MAE', color='red')\n",
    "    axes[1, 0].set_title('Mean Absolute Error')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('MAE')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Predictions vs targets\n",
    "    axes[1, 1].scatter(val_results['true_counts'], val_results['pred_counts'], alpha=0.6)\n",
    "    axes[1, 1].plot([0, max(val_results['true_counts'])], [0, max(val_results['true_counts'])], 'r--')\n",
    "    axes[1, 1].set_xlabel('True Count')\n",
    "    axes[1, 1].set_ylabel('Predicted Count')\n",
    "    axes[1, 1].set_title('Validation: Predictions vs True')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Error distribution\n",
    "    errors = val_results['pred_counts'] - val_results['true_counts']\n",
    "    axes[1, 2].hist(errors, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 2].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[1, 2].set_xlabel('Prediction Error')\n",
    "    axes[1, 2].set_ylabel('Frequency')\n",
    "    axes[1, 2].set_title('Error Distribution')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training curves\n",
    "print(\"üìà Plotting training history...\")\n",
    "plot_hybrid_training_history(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b49f25",
   "metadata": {},
   "source": [
    "# Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef075e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hybrid_predictions(\n",
    "    model: nn.Module,\n",
    "    dataset: Dataset,\n",
    "    num_samples: int = 8\n",
    ") -> None:\n",
    "    \"\"\"Visualize density maps and count predictions.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get sample data\n",
    "    indices = np.random.choice(len(dataset), min(num_samples//2, len(dataset)), replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(len(indices), 4, figsize=(16, 4*len(indices)))\n",
    "    if len(indices) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            image, true_density, true_count = dataset[idx]\n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            \n",
    "            # Get predicted density and count\n",
    "            pred_density, pred_count = model(\n",
    "                image_batch, \n",
    "                true_density_size=(true_density.shape[1], true_density.shape[2])\n",
    "            )\n",
    "            \n",
    "            # Denormalize image for visualization\n",
    "            img_viz = image.clone()\n",
    "            img_viz = img_viz * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            img_viz = torch.clamp(img_viz, 0, 1).permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Original image\n",
    "            axes[i, 0].imshow(img_viz)\n",
    "            axes[i, 0].set_title(f'Original\\nTrue: {true_count:.0f}, Pred: {pred_count.item():.1f}')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # True density map (squeeze channel dim)\n",
    "            true_density_viz = true_density.squeeze().cpu().numpy()\n",
    "            axes[i, 1].imshow(true_density_viz, cmap='hot')\n",
    "            axes[i, 1].set_title('True Density')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Predicted density map (squeeze channel dim)\n",
    "            pred_density_viz = pred_density.squeeze().cpu().numpy()\n",
    "            axes[i, 2].imshow(pred_density_viz, cmap='hot')\n",
    "            axes[i, 2].set_title('Predicted Density')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Density difference\n",
    "            diff = pred_density_viz - true_density_viz\n",
    "            im = axes[i, 3].imshow(diff, cmap='RdBu', vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)))\n",
    "            axes[i, 3].set_title('Difference')\n",
    "            axes[i, 3].axis('off')\n",
    "            \n",
    "            # Add colorbar for the first sample\n",
    "            if i == 0:\n",
    "                fig.colorbar(im, ax=axes[i, 3])\n",
    "    \n",
    "    plt.suptitle('Hybrid Model Predictions: Density Maps + Counts', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample predictions\n",
    "print(\"üé® Visualizing sample predictions...\")\n",
    "visualize_hybrid_predictions(model, val_dataset, num_samples=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08bf7ee",
   "metadata": {},
   "source": [
    "# Test Prediction and Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \"\"\"Dataset for test images.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_dir: str, transform=None) -> None:\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(\n",
    "            [f for f in os.listdir(image_dir) if f.endswith('.jpg')],\n",
    "            key=lambda x: int(os.path.splitext(x)[0])\n",
    "        )\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, str]:\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image, img_name\n",
    "\n",
    "def generate_hybrid_test_predictions(\n",
    "    model: nn.Module,\n",
    "    test_dir: str,\n",
    "    output_file: str = 'hybrid_submission.csv'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate test predictions using the hybrid model.\"\"\"\n",
    "    print(\"üìù Generating test predictions with hybrid model...\")\n",
    "    \n",
    "    test_dataset = TestDataset(test_dir, test_transforms)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    image_names = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, names in test_loader:\n",
    "            images = images.to(device)\n",
    "            pred_density, pred_count = model(images)\n",
    "            \n",
    "            # Use count predictions for submission\n",
    "            batch_preds = pred_count.cpu().numpy()\n",
    "            predictions.extend([max(0, int(round(pred))) for pred in batch_preds])\n",
    "            image_names.extend(names)\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'image_id': image_names,\n",
    "        'predicted_count': predictions\n",
    "    })\n",
    "    \n",
    "    # Sort by image_id\n",
    "    submission_df['sort_key'] = submission_df['image_id'].apply(lambda x: int(os.path.splitext(x)[0]))\n",
    "    submission_df = submission_df.sort_values('sort_key').drop('sort_key', axis=1).reset_index(drop=True)\n",
    "    \n",
    "    # Save submission\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Submission saved to {output_file}\")\n",
    "    print(f\"üìä Predictions for {len(submission_df)} test images\")\n",
    "    \n",
    "    # Statistics\n",
    "    pred_counts = submission_df['predicted_count'].values\n",
    "    print(f\"\\nüìà Test Predictions Statistics:\")\n",
    "    print(f\"Min: {pred_counts.min()}\")\n",
    "    print(f\"Max: {pred_counts.max()}\")\n",
    "    print(f\"Mean: {pred_counts.mean():.2f}\")\n",
    "    print(f\"Median: {np.median(pred_counts):.2f}\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# Generate test predictions\n",
    "submission_df = generate_hybrid_test_predictions(model, config['test_dir'], config['submission_path'])\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nüìã Sample submission:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# Plot prediction distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(submission_df['predicted_count'], bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution of Test Predictions')\n",
    "plt.xlabel('Predicted Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(submission_df['predicted_count'])\n",
    "plt.title('Test Predictions Box Plot')\n",
    "plt.ylabel('Predicted Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d5c6d",
   "metadata": {},
   "source": [
    "# Model Saving and Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saving for Competition Submission\n",
    "print(\"üíæ Saving trained model...\")\n",
    "\n",
    "# Save complete model (architecture + weights)\n",
    "model_complete_path = os.path.join(config['save_dir'], 'hybrid_counting_model_complete.pth')\n",
    "torch.save(model, model_complete_path)\n",
    "print(f\"‚úÖ Complete model saved to: {model_complete_path}\")\n",
    "\n",
    "# Save model state dict only\n",
    "model_weights_path = os.path.join(config['save_dir'], 'hybrid_counting_model_weights.pth')\n",
    "torch.save(model.state_dict(), model_weights_path)\n",
    "print(f\"‚úÖ Model weights saved to: {model_weights_path}\")\n",
    "\n",
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ HYBRID CROWD COUNTING MODEL - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüèóÔ∏è  Model Architecture: SimpleCountingNet\")\n",
    "print(f\"- CNN Backbone: Custom 4-layer CNN\")\n",
    "print(f\"- Dual outputs: Density maps + Direct count regression\")\n",
    "print(f\"- Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\nüìã Training Configuration:\")\n",
    "print(f\"- Training images: {len(train_dataset)}\")\n",
    "print(f\"- Validation images: {len(val_dataset)}\")\n",
    "print(f\"- Batch size: {config['batch_size']}\")\n",
    "print(f\"- Loss function: Hybrid (Density MSE + Count L1)\")\n",
    "\n",
    "print(f\"\\nüìä Final Performance Metrics:\")\n",
    "print(f\"- Training MAE: {train_results['mae']:.4f}\")\n",
    "print(f\"- Validation MAE: {val_results['mae']:.4f}\")\n",
    "print(f\"- Validation RMSE: {val_results['rmse']:.4f}\")\n",
    "print(f\"- Validation Correlation: {val_results['correlation']:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ Key Advantages of Hybrid Approach:\")\n",
    "print(f\"- Combines spatial density information with global count regression\")\n",
    "print(f\"- Density maps provide spatial understanding\")\n",
    "print(f\"- Count regression ensures accurate total predictions\")\n",
    "print(f\"- Mutual supervision improves both predictions\")\n",
    "\n",
    "print(f\"\\nüìù Test Set Predictions:\")\n",
    "print(f\"- Generated predictions for {len(submission_df)} test images\")\n",
    "print(f\"- Mean predicted count: {submission_df['predicted_count'].mean():.2f}\")\n",
    "print(f\"- Prediction range: {submission_df['predicted_count'].min()} to {submission_df['predicted_count'].max()}\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps for Improvement:\")\n",
    "print(f\"- Implement proper point annotations for better density maps\")\n",
    "print(f\"- Add attention mechanisms to focus on crowd regions\")\n",
    "print(f\"- Experiment with different loss function weights\")\n",
    "print(f\"- Use pretrained backbones (ResNet, EfficientNet)\")\n",
    "print(f\"- Implement multi-scale training and testing\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training and evaluation complete!\")\n",
    "print(f\"üéØ Model saved at: {config['save_dir']}\")\n",
    "print(\"üìä Evaluation results and visualizations have been generated above.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
