{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4906c99",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/FarrelAD/Hology-8-2025-Data-Mining-PRIVATE/blob/main/notebooks/scratch/nb_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79901705",
   "metadata": {},
   "source": [
    "# Crowd Counting Model\n",
    "\n",
    "This notebook implements crowd counting models.\n",
    "\n",
    "**Features:**\n",
    "- Multiple model architectures (SimpleCountingNet and ImprovedCrowdCounter)\n",
    "- Density map generation with Gaussian filtering\n",
    "- Multi-task learning approach (density + count prediction)\n",
    "- Advanced data augmentation and preprocessing\n",
    "- Model evaluation and visualization\n",
    "- Enhanced loss functions with multi-task optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7020d804",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea857fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries and Setup\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "from typing import List, Tuple, Dict, Any, Union, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "\n",
    "# Detect environment\n",
    "def detect_environment():\n",
    "    \"\"\"Detect if running in Colab, Kaggle, or local environment\"\"\"\n",
    "    if 'google.colab' in sys.modules:\n",
    "        return 'colab'\n",
    "    elif 'kaggle_secrets' in sys.modules or os.environ.get('KAGGLE_KERNEL_RUN_TYPE'):\n",
    "        return 'kaggle'\n",
    "    else:\n",
    "        return 'local'\n",
    "\n",
    "ENV = detect_environment()\n",
    "print(f\"ðŸ” Detected environment: {ENV.upper()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ”§ Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d6ae9f",
   "metadata": {},
   "source": [
    "# Dataset Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment-specific dataset setup\n",
    "def setup_dataset_paths(env: str) -> Dict[str, str]:\n",
    "    \"\"\"Setup dataset paths based on environment\"\"\"\n",
    "    \n",
    "    if env == 'colab':\n",
    "        # Google Colab paths\n",
    "        dataset_name = \"penyisihan-hology-8-0-2025-data-mining\"\n",
    "        drive_path = \"/content/drive/MyDrive/PROJECTS/Cognivio/dataset\"\n",
    "        local_path = \"/content/dataset\"\n",
    "        \n",
    "        # Mount Google Drive and setup Kaggle credentials\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        \n",
    "        # Setup dataset download logic here...\n",
    "        \n",
    "        return {\n",
    "            'img_dir': f\"{local_path}/train/images\",\n",
    "            'label_dir': f\"{local_path}/train/labels\", \n",
    "            'test_dir': f\"{local_path}/test/images\",\n",
    "            'save_dir': \"/content/drive/MyDrive/PROJECTS/Cognivio/models\"\n",
    "        }\n",
    "    \n",
    "    elif env == 'kaggle':\n",
    "        # Kaggle paths\n",
    "        return {\n",
    "            'img_dir': \"/kaggle/input/penyisihan-hology-8-0-2025-data-mining/train/images\",\n",
    "            'label_dir': \"/kaggle/input/penyisihan-hology-8-0-2025-data-mining/train/labels\",\n",
    "            'test_dir': \"/kaggle/input/penyisihan-hology-8-0-2025-data-mining/test/images\",\n",
    "            'save_dir': \"/kaggle/working\"\n",
    "        }\n",
    "    \n",
    "    else:  # local\n",
    "        # Local paths\n",
    "        base_path = \"../../data\"\n",
    "        return {\n",
    "            'img_dir': f\"{base_path}/train/images\",\n",
    "            'label_dir': f\"{base_path}/train/labels\",\n",
    "            'test_dir': f\"{base_path}/test/images\",\n",
    "            'save_dir': r\"d:\\Hology\\Hology-8-2025-Data-Mining-PRIVATE\"\n",
    "        }\n",
    "\n",
    "# Setup paths\n",
    "paths = setup_dataset_paths(ENV)\n",
    "print(f\"ðŸ“ Dataset paths configured for {ENV}:\")\n",
    "for key, path in paths.items():\n",
    "    exists = \"âœ…\" if os.path.exists(path) else \"âš ï¸\"\n",
    "    print(f\"   {key}: {path} {exists}\")\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(paths['save_dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de732a5",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d686eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "config = {\n",
    "    # Data paths\n",
    "    'img_dir': paths['img_dir'],\n",
    "    'label_dir': paths['label_dir'],\n",
    "    'test_dir': paths['test_dir'],\n",
    "    'save_dir': paths['save_dir'],\n",
    "    \n",
    "    # Model parameters\n",
    "    'target_size': (512, 512),\n",
    "    'batch_size': 4,\n",
    "    'epochs': 50,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    \n",
    "    # Training parameters\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True,\n",
    "    'early_stop_patience': 5,\n",
    "    \n",
    "    # Model saving\n",
    "    'simple_model_path': os.path.join(paths['save_dir'], 'best_simple_model.pth'),\n",
    "    'improved_model_path': os.path.join(paths['save_dir'], 'improved_counting_best.pth'),\n",
    "    'submission_path': os.path.join(paths['save_dir'], 'submission_improved_model.csv'),\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"ðŸ“‹ Configuration loaded:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af6a68e",
   "metadata": {},
   "source": [
    "# Set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca415b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(config['seed'])\n",
    "print(f\"ðŸŽ² Random seed set to {config['seed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebef5bf",
   "metadata": {},
   "source": [
    "# Data Analysis and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ðŸ” Analyzing dataset...\")\n",
    "\n",
    "# Check dataset sizes\n",
    "train_images = os.listdir(config['img_dir'])\n",
    "train_labels = os.listdir(config['label_dir'])\n",
    "test_images = os.listdir(config['test_dir'])\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Overview:\")\n",
    "print(f\"Train images: {len(train_images)}\")\n",
    "print(f\"Train labels: {len(train_labels)}\")\n",
    "print(f\"Test images: {len(test_images)}\")\n",
    "\n",
    "# Load and examine sample labels\n",
    "print(f\"\\nðŸ” Sample label examination:\")\n",
    "sample_labels = []\n",
    "for i, label_file in enumerate(train_labels[:3]):\n",
    "    with open(os.path.join(config['label_dir'], label_file), 'r') as f:\n",
    "        label_data = json.load(f)\n",
    "        sample_labels.append(label_data)\n",
    "        print(f\"Sample {i+1}: {label_file}\")\n",
    "        print(f\"  Image ID: {label_data['img_id']}\")\n",
    "        print(f\"  Human count: {label_data['human_num']}\")\n",
    "        print(f\"  Number of points: {len(label_data['points'])}\")\n",
    "\n",
    "# Analyze crowd count distribution\n",
    "crowd_counts = []\n",
    "for label_file in train_labels:\n",
    "    with open(os.path.join(config['label_dir'], label_file), 'r') as f:\n",
    "        label_data = json.load(f)\n",
    "        crowd_counts.append(label_data['human_num'])\n",
    "\n",
    "crowd_counts = np.array(crowd_counts)\n",
    "print(f\"\\nðŸ“ˆ Crowd count statistics:\")\n",
    "print(f\"Mean: {crowd_counts.mean():.2f}\")\n",
    "print(f\"Std: {crowd_counts.std():.2f}\")\n",
    "print(f\"Min: {crowd_counts.min()}\")\n",
    "print(f\"Max: {crowd_counts.max()}\")\n",
    "print(f\"Median: {np.median(crowd_counts):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da57b04",
   "metadata": {},
   "source": [
    "# Visualize distribution and sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c78f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(crowd_counts, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution of Crowd Counts')\n",
    "plt.xlabel('Number of People')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.boxplot(crowd_counts)\n",
    "plt.title('Crowd Count Box Plot')\n",
    "plt.ylabel('Number of People')\n",
    "\n",
    "# Load and visualize sample images with annotations\n",
    "sample_img_path = os.path.join(config['img_dir'], \"1.jpg\")\n",
    "sample_label_path = os.path.join(config['label_dir'], \"1.json\")\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread(sample_img_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Load annotations\n",
    "with open(sample_label_path, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(img_rgb)\n",
    "# Plot annotation points\n",
    "points = annotations['points']\n",
    "x_coords = [p['x'] for p in points]\n",
    "y_coords = [p['y'] for p in points]\n",
    "plt.scatter(x_coords, y_coords, c='red', s=10, alpha=0.6)\n",
    "plt.title(f'Sample Image: {annotations[\"human_num\"]} people')\n",
    "plt.axis('off')\n",
    "\n",
    "# Visualize another sample\n",
    "sample_img_path2 = os.path.join(config['img_dir'], \"100.jpg\")\n",
    "sample_label_path2 = os.path.join(config['label_dir'], \"100.json\")\n",
    "\n",
    "img2 = cv2.imread(sample_img_path2)\n",
    "img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "with open(sample_label_path2, 'r') as f:\n",
    "    annotations2 = json.load(f)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(img2_rgb)\n",
    "points2 = annotations2['points']\n",
    "x_coords2 = [p['x'] for p in points2]\n",
    "y_coords2 = [p['y'] for p in points2]\n",
    "plt.scatter(x_coords2, y_coords2, c='red', s=15, alpha=0.8)\n",
    "plt.title(f'Sample Image: {annotations2[\"human_num\"]} people')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d751a8",
   "metadata": {},
   "source": [
    "# Dataset Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrowdCountingDataset(Dataset):\n",
    "    \"\"\"Custom dataset for crowd counting with density map generation.\n",
    "    \n",
    "    Supports density map generation using Gaussian filtering and various\n",
    "    data augmentation options.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        images_dir: str,\n",
    "        labels_dir: str,\n",
    "        transform: Optional[Any] = None,\n",
    "        target_size: Tuple[int, int] = (512, 512)\n",
    "    ) -> None:\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "        self.image_files.sort()\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # Load image\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load annotations\n",
    "        label_name = img_name.replace('.jpg', '.json')\n",
    "        label_path = os.path.join(self.labels_dir, label_name)\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            label_data = json.load(f)\n",
    "        \n",
    "        # Get original image dimensions\n",
    "        orig_h, orig_w = image.shape[:2]\n",
    "        \n",
    "        # Resize image\n",
    "        image = cv2.resize(image, self.target_size)\n",
    "        \n",
    "        # Create density map\n",
    "        density_map = self.create_density_map(\n",
    "            label_data['points'], orig_w, orig_h, self.target_size\n",
    "        )\n",
    "        \n",
    "        # Apply transforms if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            # Convert to tensor and normalize\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "        density_map = torch.from_numpy(density_map).float()\n",
    "        count = torch.tensor(label_data['human_num'], dtype=torch.float32)\n",
    "        \n",
    "        return image, density_map, count\n",
    "    \n",
    "    def create_density_map(\n",
    "        self,\n",
    "        points: List[Dict[str, float]],\n",
    "        orig_w: int,\n",
    "        orig_h: int,\n",
    "        target_size: Tuple[int, int]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Create Gaussian density map from point annotations\"\"\"\n",
    "        # Scale factor for resizing\n",
    "        scale_x = target_size[0] / orig_w\n",
    "        scale_y = target_size[1] / orig_h\n",
    "        \n",
    "        # Initialize density map\n",
    "        density_map = np.zeros(target_size[::-1], dtype=np.float32)  # (height, width)\n",
    "        \n",
    "        if len(points) == 0:\n",
    "            return density_map\n",
    "        \n",
    "        # Scale points to new dimensions\n",
    "        scaled_points = []\n",
    "        for point in points:\n",
    "            x_scaled = point['x'] * scale_x\n",
    "            y_scaled = point['y'] * scale_y\n",
    "            \n",
    "            # Ensure points are within bounds\n",
    "            x_scaled = max(0, min(target_size[0] - 1, x_scaled))\n",
    "            y_scaled = max(0, min(target_size[1] - 1, y_scaled))\n",
    "            \n",
    "            scaled_points.append((int(x_scaled), int(y_scaled)))\n",
    "        \n",
    "        # Create Gaussian kernels for each point\n",
    "        sigma = 4.0  # Standard deviation for Gaussian kernel\n",
    "        kernel_size = int(6 * sigma)  # Kernel size (6 sigma rule)\n",
    "        \n",
    "        for x, y in scaled_points:\n",
    "            # Create Gaussian kernel\n",
    "            y_min = max(0, y - kernel_size)\n",
    "            y_max = min(target_size[1], y + kernel_size + 1)\n",
    "            x_min = max(0, x - kernel_size)\n",
    "            x_max = min(target_size[0], x + kernel_size + 1)\n",
    "            \n",
    "            # Generate mesh grid for the region\n",
    "            yy, xx = np.meshgrid(range(y_min, y_max), range(x_min, x_max), indexing='ij')\n",
    "            \n",
    "            # Calculate Gaussian values\n",
    "            gaussian = np.exp(-((xx - x) ** 2 + (yy - y) ** 2) / (2 * sigma ** 2))\n",
    "            \n",
    "            # Add to density map\n",
    "            density_map[y_min:y_max, x_min:x_max] += gaussian\n",
    "        \n",
    "        return density_map\n",
    "\n",
    "print(\"âœ… CrowdCountingDataset class implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f54e7",
   "metadata": {},
   "source": [
    "# Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count parameters\n",
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Simple Model Definition\n",
    "class SimpleCountingNet(nn.Module):\n",
    "    \"\"\"Simple CNN-based crowd counting model with dual outputs.\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super(SimpleCountingNet, self).__init__()\n",
    "        \n",
    "        # Simple CNN backbone\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Density regression head\n",
    "        self.density_head = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Count regression head\n",
    "        self.count_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Extract features\n",
    "        features = self.features(x)\n",
    "        \n",
    "        # Density map prediction\n",
    "        density = self.density_head(features)\n",
    "        # Upsample to quarter resolution\n",
    "        density = F.interpolate(density, scale_factor=8, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Count prediction\n",
    "        count = self.count_head(features).squeeze()\n",
    "        \n",
    "        return density, count\n",
    "\n",
    "# Improved model with better architecture\n",
    "class ImprovedCrowdCounter(nn.Module):\n",
    "    \"\"\"Advanced crowd counting model with ResNet-like architecture.\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super(ImprovedCrowdCounter, self).__init__()\n",
    "        \n",
    "        # Use ResNet-like blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.layer1 = self._make_layer(64, 128, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 512, 2, stride=2)\n",
    "        \n",
    "        # Density estimation branch\n",
    "        self.density_branch = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Count estimation branch (global)\n",
    "        self.count_branch = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _make_layer(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        num_blocks: int,\n",
    "        stride: int = 1\n",
    "    ) -> nn.Sequential:\n",
    "        layers = []\n",
    "        # First block (may downsample)\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1))\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Remaining blocks\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(nn.Conv2d(out_channels, out_channels, 3, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Feature extraction\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        features = self.layer3(x)\n",
    "        \n",
    "        # Density estimation\n",
    "        density = self.density_branch(features)\n",
    "        \n",
    "        # Upsample density to quarter resolution\n",
    "        density = F.interpolate(density, scale_factor=4, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # Count estimation\n",
    "        count = self.count_branch(features).squeeze()\n",
    "        \n",
    "        return density, count\n",
    "    \n",
    "    def _initialize_weights(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "print(\"âœ… Model architectures implemented!\")\n",
    "\n",
    "# Test model instantiation\n",
    "print(\"ðŸ” Testing model architectures...\")\n",
    "simple_test = SimpleCountingNet().to(device)\n",
    "improved_test = ImprovedCrowdCounter().to(device)\n",
    "\n",
    "print(f\"ðŸ“Š SimpleCountingNet parameters: {count_parameters(simple_test):,}\")\n",
    "print(f\"ðŸ“Š ImprovedCrowdCounter parameters: {count_parameters(improved_test):,}\")\n",
    "\n",
    "del simple_test, improved_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c7cba",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448830d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic CrowdCountingLoss for backward compatibility \n",
    "class CrowdCountingLoss(nn.Module):\n",
    "    \"\"\"Multi-task loss for crowd counting with density and count predictions.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 1.0, beta: float = 1.0) -> None:\n",
    "        super(CrowdCountingLoss, self).__init__()\n",
    "        self.alpha = alpha  # density loss weight\n",
    "        self.beta = beta    # count loss weight\n",
    "        \n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        density_pred: torch.Tensor,\n",
    "        count_pred: torch.Tensor,\n",
    "        density_target: torch.Tensor,\n",
    "        count_target: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        # Density map loss\n",
    "        density_loss = self.mse(density_pred, density_target)\n",
    "        \n",
    "        # Count loss  \n",
    "        count_loss = self.mse(count_pred, count_target.float())\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = self.alpha * density_loss + self.beta * count_loss\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "# Multi-task loss for both density and count\n",
    "class MultiTaskLoss(nn.Module):\n",
    "    \"\"\"Enhanced multi-task loss with separate loss components.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 1.0, beta: float = 1.0) -> None:\n",
    "        super(MultiTaskLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        pred_density: torch.Tensor,\n",
    "        true_density: torch.Tensor,\n",
    "        pred_count: torch.Tensor,\n",
    "        true_count: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        density_loss = self.mse(pred_density, true_density)\n",
    "        count_loss = self.mse(pred_count, true_count)\n",
    "        \n",
    "        total_loss = self.alpha * density_loss + self.beta * count_loss\n",
    "        return total_loss, density_loss, count_loss\n",
    "\n",
    "print(\"âœ… Loss functions implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd809b2",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” Preparing datasets...\")\n",
    "\n",
    "# Data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "full_dataset = CrowdCountingDataset(\n",
    "    config['img_dir'],\n",
    "    config['label_dir'],\n",
    "    target_size=config['target_size']\n",
    ")\n",
    "\n",
    "# Split dataset (80% train, 20% validation)\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, val_size], \n",
    "    generator=torch.Generator().manual_seed(config['seed'])\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“¦ Dataset sizes: Train={len(train_dataset)}, Val={len(val_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=config['pin_memory'],\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=config['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"ðŸš€ Data loaders created!\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Test the dataset\n",
    "sample_img, sample_density, sample_count = full_dataset[0]\n",
    "print(f\"ðŸ“Š Sample data shapes:\")\n",
    "print(f\"   Image: {sample_img.shape}\")\n",
    "print(f\"   Density map: {sample_density.shape}\")\n",
    "print(f\"   Count: {sample_count}, Density sum: {sample_density.sum():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beefd28f",
   "metadata": {},
   "source": [
    "# Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d35b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_improved(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    epochs: int = 15,\n",
    "    lr: float = 0.001,\n",
    "    weight_decay: float = 1e-4,\n",
    "    save_path: str = 'best_model.pth'\n",
    ") -> Tuple[List[float], List[float], List[float], List[float], float]:\n",
    "    \"\"\"\n",
    "    Improved training with better hyperparameters and early stopping\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Use AdamW optimizer with weight decay\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = CrowdCountingLoss(alpha=1.0, beta=0.01)  \n",
    "    \n",
    "    # Training history\n",
    "    train_losses, val_losses = [], []\n",
    "    train_maes, val_maes = [], []\n",
    "    \n",
    "    best_mae = float('inf')\n",
    "    patience = 0\n",
    "    patience_limit = config['early_stop_patience']\n",
    "    \n",
    "    print(f\"ðŸš€ Starting training for {epochs} epochs...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nðŸ“ˆ Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        running_train_mae = 0.0\n",
    "        \n",
    "        for batch_idx, (images, density_maps, counts) in enumerate(tqdm(train_loader, desc=\"Train\", leave=False)):\n",
    "            images = images.to(device)\n",
    "            density_maps = density_maps.to(device)  \n",
    "            counts = counts.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred_density, pred_counts = model(images)\n",
    "            \n",
    "            loss = criterion(pred_density, pred_counts, density_maps, counts)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_train_loss += loss.item()\n",
    "            \n",
    "            # Calculate MAE for count prediction\n",
    "            mae = torch.mean(torch.abs(pred_counts - counts)).item()\n",
    "            running_train_mae += mae\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        running_val_mae = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, density_maps, counts in tqdm(val_loader, desc=\"Val\", leave=False):\n",
    "                images = images.to(device)\n",
    "                density_maps = density_maps.to(device)\n",
    "                counts = counts.to(device)\n",
    "                \n",
    "                pred_density, pred_counts = model(images)\n",
    "                loss = criterion(pred_density, pred_counts, density_maps, counts)\n",
    "                \n",
    "                running_val_loss += loss.item()\n",
    "                mae = torch.mean(torch.abs(pred_counts - counts)).item()\n",
    "                running_val_mae += mae\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        epoch_train_mae = running_train_mae / len(train_loader)\n",
    "        epoch_val_mae = running_val_mae / len(val_loader)\n",
    "        \n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        train_maes.append(epoch_train_mae)\n",
    "        val_maes.append(epoch_val_mae)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"ðŸ“Š Train Loss: {epoch_train_loss:.4f}, Train MAE: {epoch_train_mae:.2f}\")\n",
    "        print(f\"ðŸ“Š Val Loss: {epoch_val_loss:.4f}, Val MAE: {epoch_val_mae:.2f}\")\n",
    "        print(f\"ðŸŽ¯ Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Save best model based on validation MAE\n",
    "        if epoch_val_mae < best_mae:\n",
    "            best_mae = epoch_val_mae\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"âœ… New best model saved! MAE: {best_mae:.2f}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            print(f\"â³ No improvement for {patience} epoch(s)\")\n",
    "    \n",
    "    return train_losses, val_losses, train_maes, val_maes, best_mae\n",
    "\n",
    "def train_multitask_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    epochs: int = 20,\n",
    "    lr: float = 1e-4\n",
    ") -> Tuple[List[float], List[float], List[float], List[float], float]:\n",
    "    \"\"\"Improved training function for multi-task model\"\"\"\n",
    "    \n",
    "    criterion = MultiTaskLoss(alpha=0.1, beta=1.0)  # Emphasize count loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, 'min', patience=5, factor=0.5, verbose=True\n",
    "    )\n",
    "    \n",
    "    best_mae = float('inf')\n",
    "    train_losses, val_losses = [], []\n",
    "    train_maes, val_maes = [], []\n",
    "    \n",
    "    print(f\"ðŸš€ Starting multi-task training for {epochs} epochs...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nðŸ“ˆ Epoch {epoch+1}/{epochs}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_mae = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc='Training')\n",
    "        for images, density_maps, counts in pbar:\n",
    "            images = images.to(device)\n",
    "            density_maps = density_maps.to(device).unsqueeze(1)\n",
    "            counts = counts.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward\n",
    "            pred_density, pred_count = model(images)\n",
    "            \n",
    "            # Resize density map if needed\n",
    "            if pred_density.shape != density_maps.shape:\n",
    "                pred_density = F.interpolate(\n",
    "                    pred_density, size=density_maps.shape[2:], \n",
    "                    mode='bilinear', align_corners=False\n",
    "                )\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss, density_loss, count_loss = criterion(\n",
    "                pred_density, density_maps, pred_count, counts\n",
    "            )\n",
    "            \n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Metrics\n",
    "            mae = torch.abs(pred_count - counts).mean().item()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_mae += mae\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}', \n",
    "                'MAE': f'{mae:.2f}', \n",
    "                'D_Loss': f'{density_loss.item():.4f}',\n",
    "                'C_Loss': f'{count_loss.item():.4f}'\n",
    "            })\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        avg_train_mae = epoch_mae / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_mae = 0\n",
    "        val_mse = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, density_maps, counts in val_loader:\n",
    "                images = images.to(device)\n",
    "                density_maps = density_maps.to(device).unsqueeze(1)\n",
    "                counts = counts.to(device)\n",
    "                \n",
    "                pred_density, pred_count = model(images)\n",
    "                \n",
    "                if pred_density.shape != density_maps.shape:\n",
    "                    pred_density = F.interpolate(\n",
    "                        pred_density, size=density_maps.shape[2:], \n",
    "                        mode='bilinear', align_corners=False\n",
    "                    )\n",
    "                \n",
    "                loss, _, _ = criterion(pred_density, density_maps, pred_count, counts)\n",
    "                mae = torch.abs(pred_count - counts).mean().item()\n",
    "                mse = ((pred_count - counts) ** 2).mean().item()\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_mae += mae\n",
    "                val_mse += mse\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_mae = val_mae / len(val_loader)\n",
    "        val_rmse = np.sqrt(val_mse / len(val_loader))\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_maes.append(avg_train_mae)\n",
    "        val_maes.append(avg_val_mae)\n",
    "        \n",
    "        print(f\"ðŸ“Š Train Loss: {avg_train_loss:.4f}, Train MAE: {avg_train_mae:.2f}\")\n",
    "        print(f\"ðŸ“Š Val Loss: {avg_val_loss:.4f}, Val MAE: {avg_val_mae:.2f}, Val RMSE: {val_rmse:.2f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_mae < best_mae:\n",
    "            best_mae = avg_val_mae\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'best_mae': best_mae,\n",
    "            }, config['improved_model_path'])\n",
    "            print(f\"âœ… New best model saved! MAE: {best_mae:.2f}\")\n",
    "    \n",
    "    return train_losses, val_losses, train_maes, val_maes, best_mae\n",
    "\n",
    "print(\"âœ… Training functions implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e071129",
   "metadata": {},
   "source": [
    "## Training - Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15ed7e",
   "metadata": {},
   "source": [
    "### Initialize Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad680f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ—ï¸ Training Simple Model...\")\n",
    "\n",
    "# Initialize simple model\n",
    "simple_model = SimpleCountingNet().to(device)\n",
    "print(f\"ðŸ“Š Simple model parameters: {count_parameters(simple_model):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb86a6",
   "metadata": {},
   "source": [
    "### Train the simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸš€ Starting simple model training...\")\n",
    "simple_train_losses, simple_val_losses, simple_train_maes, simple_val_maes, simple_best_mae = train_model_improved(\n",
    "    simple_model, train_loader, val_loader, \n",
    "    epochs=15, lr=0.001, weight_decay=1e-4,\n",
    "    save_path=config['simple_model_path']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298dc1d",
   "metadata": {},
   "source": [
    "### Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dcecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… Simple Model Training Complete - Best MAE: {simple_best_mae:.2f}\")\n",
    "\n",
    "# Plot simple model training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(simple_train_losses, label='Training Loss')\n",
    "plt.plot(simple_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Simple Model: Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(simple_train_maes, label='Training MAE')\n",
    "plt.plot(simple_val_maes, label='Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Simple Model: Training vs Validation MAE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(simple_val_maes)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.title('Simple Model: Validation MAE Progress')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac8be5",
   "metadata": {},
   "source": [
    "## Training - Improved Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a3414",
   "metadata": {},
   "source": [
    "### Initialize improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b373e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ—ï¸ Training Improved Model...\")\n",
    "\n",
    "improved_model = ImprovedCrowdCounter().to(device)\n",
    "print(f\"ðŸ“Š Improved model parameters: {count_parameters(improved_model):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef08e0c",
   "metadata": {},
   "source": [
    "### Train the improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸš€ Starting improved model training...\")\n",
    "improved_train_losses, improved_val_losses, improved_train_maes, improved_val_maes, improved_best_mae = train_multitask_model(\n",
    "    improved_model, train_loader, val_loader, epochs=20, lr=1e-4\n",
    ")\n",
    "\n",
    "print(f\"âœ… Improved Model Training Complete - Best MAE: {improved_best_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0deacb",
   "metadata": {},
   "source": [
    "### Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b010dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot improved model training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(improved_train_losses, label='Train Loss')\n",
    "plt.plot(improved_val_losses, label='Val Loss')\n",
    "plt.title('Improved Model: Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(improved_train_maes, label='Train MAE')\n",
    "plt.plot(improved_val_maes, label='Val MAE')\n",
    "plt.title('Improved Model: Training and Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a2f5db",
   "metadata": {},
   "source": [
    "# Load best improved model for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = config['improved_model_path']\n",
    "if os.path.exists(best_model_path):\n",
    "    checkpoint = torch.load(best_model_path, map_location=device)\n",
    "    improved_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"âœ… Loaded best model with MAE: {checkpoint['best_mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4003d1",
   "metadata": {},
   "source": [
    "# Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a778ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_improved_predictions(\n",
    "    model: nn.Module,\n",
    "    dataset: Dataset,\n",
    "    num_samples: int = 4\n",
    ") -> None:\n",
    "    \"\"\"Visualize model predictions with density maps.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(3, num_samples, figsize=(4*num_samples, 12))\n",
    "    \n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            image, true_density, true_count = dataset[idx]\n",
    "            \n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            pred_density, pred_count = model(image_batch)\n",
    "            \n",
    "            if pred_density.shape[2:] != true_density.shape:\n",
    "                pred_density = F.interpolate(\n",
    "                    pred_density, size=true_density.shape, \n",
    "                    mode='bilinear', align_corners=False\n",
    "                )\n",
    "            \n",
    "            image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "            true_density_np = true_density.cpu().numpy()\n",
    "            pred_density_np = pred_density.squeeze().cpu().numpy()\n",
    "            pred_count_val = pred_count.item()\n",
    "            \n",
    "            # Original image\n",
    "            axes[0, i].imshow(image_np)\n",
    "            axes[0, i].set_title(f'Original\\nTrue: {true_count:.0f}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # True density\n",
    "            im1 = axes[1, i].imshow(true_density_np, cmap='jet')\n",
    "            axes[1, i].set_title(f'True Density\\nSum: {true_density_np.sum():.0f}')\n",
    "            axes[1, i].axis('off')\n",
    "            plt.colorbar(im1, ax=axes[1, i], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            # Predicted density\n",
    "            im2 = axes[2, i].imshow(pred_density_np, cmap='jet')\n",
    "            axes[2, i].set_title(f'Predicted\\nCount: {pred_count_val:.0f}')\n",
    "            axes[2, i].axis('off')\n",
    "            plt.colorbar(im2, ax=axes[2, i], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"ðŸŽ¨ Visualizing improved model predictions...\")\n",
    "visualize_improved_predictions(improved_model, val_dataset, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dec035",
   "metadata": {},
   "source": [
    "# Test Prediction and Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_improved_predictions(\n",
    "    model: nn.Module,\n",
    "    test_images_path: str,\n",
    "    test_image_names: List[str],\n",
    "    device: str = 'cuda'\n",
    ") -> List[int]:\n",
    "    \"\"\"Create predictions for test set with improved model\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    print(\"ðŸ“ Creating predictions with improved model...\")\n",
    "    \n",
    "    for image_name in tqdm(test_image_names, desc=\"Predicting\"):\n",
    "        image_path = os.path.join(test_images_path, image_name)\n",
    "        \n",
    "        if os.path.exists(image_path):\n",
    "            # Load image\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, config['target_size'])\n",
    "            \n",
    "            # Convert to tensor\n",
    "            image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "            image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                _, pred_count = model(image_tensor)\n",
    "                predicted_count = max(0, int(round(pred_count.item())))\n",
    "                predictions.append(predicted_count)\n",
    "        else:\n",
    "            print(f\"âš ï¸ Warning: {image_name} not found\")\n",
    "            predictions.append(0)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Create submission DataFrame structure\n",
    "submission_df = pd.DataFrame({\n",
    "    'image_id': [int(os.path.splitext(f)[0]) for f in test_images],\n",
    "    'predicted_count': [0] * len(test_images)  # Placeholder\n",
    "})\n",
    "submission_df = submission_df.sort_values('image_id').reset_index(drop=True)\n",
    "\n",
    "# Generate final predictions\n",
    "final_predictions = create_improved_predictions(\n",
    "    improved_model, config['test_dir'], test_images, device=device\n",
    ")\n",
    "\n",
    "# Update submission\n",
    "submission_df['predicted_count'] = final_predictions\n",
    "\n",
    "print(\"ðŸ“‹ Final predictions sample:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Final prediction statistics:\")\n",
    "print(f\"Mean: {np.mean(final_predictions):.2f}\")\n",
    "print(f\"Std: {np.std(final_predictions):.2f}\")\n",
    "print(f\"Min: {np.min(final_predictions)}\")\n",
    "print(f\"Max: {np.max(final_predictions)}\")\n",
    "\n",
    "# Save final submission\n",
    "submission_df.to_csv(config['submission_path'], index=False)\n",
    "print(f\"âœ… Final predictions saved to: {config['submission_path']}\")\n",
    "\n",
    "# Plot final prediction distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(final_predictions, bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution of Final Test Predictions')\n",
    "plt.xlabel('Predicted Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(final_predictions)\n",
    "plt.title('Final Test Predictions Box Plot')\n",
    "plt.ylabel('Predicted Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d3a3e0",
   "metadata": {},
   "source": [
    "# Model Saving and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6941de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model metadata\n",
    "model_metadata = {\n",
    "    \"models_trained\": [\"SimpleCountingNet\", \"ImprovedCrowdCounter\"],\n",
    "    \"simple_model\": {\n",
    "        \"architecture\": \"Simple CNN with dual outputs\",\n",
    "        \"best_validation_mae\": float(simple_best_mae),\n",
    "        \"total_parameters\": count_parameters(simple_model),\n",
    "        \"save_path\": config['simple_model_path']\n",
    "    },\n",
    "    \"improved_model\": {\n",
    "        \"architecture\": \"Multi-task ResNet-like with density + count estimation\",\n",
    "        \"best_validation_mae\": float(improved_best_mae),\n",
    "        \"total_parameters\": count_parameters(improved_model),\n",
    "        \"save_path\": config['improved_model_path']\n",
    "    },\n",
    "    \"dataset_info\": {\n",
    "        \"training_images\": len(train_dataset),\n",
    "        \"validation_images\": len(val_dataset),\n",
    "        \"test_images\": len(test_images)\n",
    "    },\n",
    "    \"final_predictions\": {\n",
    "        \"range\": [int(np.min(final_predictions)), int(np.max(final_predictions))],\n",
    "        \"mean\": float(np.mean(final_predictions)),\n",
    "        \"submission_path\": config['submission_path']\n",
    "    },\n",
    "    \"created_date\": datetime.now().isoformat(),\n",
    "    \"use_case\": \"Festival Harmoni Nusantara - Crowd Monitoring\"\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = os.path.join(config['save_dir'], 'model_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ‰ CROWD COUNTING MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… Dataset: {len(train_dataset)} train, {len(val_dataset)} val, {len(test_images)} test images\")\n",
    "print(f\"âœ… Simple Model - Best validation MAE: {simple_best_mae:.2f}\")\n",
    "print(f\"âœ… Improved Model - Best validation MAE: {improved_best_mae:.2f}\")\n",
    "print(f\"âœ… Final predictions range: {np.min(final_predictions)} - {np.max(final_predictions)} people\")\n",
    "print(f\"âœ… Average predicted count: {np.mean(final_predictions):.1f} people\")\n",
    "print(f\"âœ… Submission file: {os.path.basename(config['submission_path'])}\")\n",
    "print(f\"âœ… Model metadata saved to: {os.path.basename(metadata_path)}\")\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸš€ Ready for Festival Harmoni Nusantara deployment!\")\n",
    "\n",
    "print(\"\\nðŸ“ FILES GENERATED:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"âœ“ Simple Model: {os.path.basename(config['simple_model_path'])}\")\n",
    "print(f\"âœ“ Improved Model: {os.path.basename(config['improved_model_path'])}\")\n",
    "print(f\"âœ“ Final Predictions: {os.path.basename(config['submission_path'])}\")\n",
    "print(f\"âœ“ Model Metadata: {os.path.basename(metadata_path)}\")\n",
    "\n",
    "# Validation check\n",
    "submission_check = pd.read_csv(config['submission_path'])\n",
    "print(f\"\\nðŸ“Š SUBMISSION FILE VALIDATION:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"âœ“ Shape: {submission_check.shape}\")\n",
    "print(f\"âœ“ Columns: {list(submission_check.columns)}\")\n",
    "print(f\"âœ“ Data types: {submission_check.dtypes.to_dict()}\")\n",
    "print(f\"âœ“ No missing values: {submission_check.isnull().sum().sum() == 0}\")\n",
    "print(f\"âœ“ All predictions non-negative: {(submission_check['predicted_count'] >= 0).all()}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ PROJECT COMPLETION STATUS:\")\n",
    "print(\"=\"*50)\n",
    "print(\"âœ… Dataset Analysis - COMPLETED\")\n",
    "print(\"âœ… Model Architecture Design - COMPLETED\") \n",
    "print(\"âœ… Data Preprocessing Pipeline - COMPLETED\")\n",
    "print(\"âœ… Model Training & Validation - COMPLETED\")\n",
    "print(\"âœ… Performance Evaluation - COMPLETED\")\n",
    "print(\"âœ… Test Set Predictions - COMPLETED\")\n",
    "print(\"âœ… Submission File Generation - COMPLETED\")\n",
    "print(\"âœ… Documentation & Visualization - COMPLETED\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
