{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe58c557",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/FarrelAD/Hology-8-2025-Data-Mining-PRIVATE/blob/dev%2Fvidi/notebooks/vidi/nb_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f496bb3",
   "metadata": {},
   "source": [
    "# 1. Project Setup and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c15b9",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ffc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import scipy.ndimage\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f51e7f",
   "metadata": {},
   "source": [
    "## Dataset Download and Setup\n",
    "Keep the same dataset download code as reference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21175fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-9fab1f83-9952-45f0-8ecc-486ff2cb590e\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-9fab1f83-9952-45f0-8ecc-486ff2cb590e\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "User uploaded file \"kaggle.json\" with length 64 bytes\n"
     ]
    }
   ],
   "source": [
    "# @title Setup Kaggle secret key\n",
    "!pip install -q kaggle\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "\n",
    "# Then move kaggle.json into the folder where the API expects to find it.\n",
    "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60917497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Dataset not found locally, downloading...\n",
      "Downloading penyisihan-hology-8-0-2025-data-mining.zip to /content\n",
      " 60% 125M/209M [00:00<00:00, 1.30GB/s]\n",
      "100% 209M/209M [00:00<00:00, 791MB/s] \n",
      "Dataset already extracted at: /content/drive/MyDrive/PROJECTS/Cognivio/Percobaan Hology 8 2025/dataset\n",
      "Copying dataset to Colab local storage (/content)...\n",
      "Train images: /content/dataset/train/images\n",
      "Train labels: /content/dataset/train/labels\n",
      "Test images: /content/dataset/test/images\n"
     ]
    }
   ],
   "source": [
    "# @title Setup dataset in Colab\n",
    "import zipfile\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Paths\n",
    "zip_path = \"/content/penyisihan-hology-8-0-2025-data-mining.zip\"\n",
    "drive_extract_path = \"/content/drive/MyDrive/PROJECTS/Cognivio/Percobaan Hology 8 2025/dataset\"\n",
    "local_dataset_path = \"/content/dataset\"  # for current session\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Download zip (if not exists in /content)\n",
    "# ---------------------------\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Dataset not found locally, downloading...\")\n",
    "    !kaggle competitions download -c penyisihan-hology-8-0-2025-data-mining -p /content\n",
    "else:\n",
    "    print(\"Dataset already exists, skipping download.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Extract to Google Drive (for backup)\n",
    "# ---------------------------\n",
    "os.makedirs(drive_extract_path, exist_ok=True)\n",
    "\n",
    "if not os.listdir(drive_extract_path):  # Check if folder is empty\n",
    "    print(\"Extracting dataset to Google Drive...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(drive_extract_path)\n",
    "    print(\"Dataset extracted to:\", drive_extract_path)\n",
    "else:\n",
    "    print(\"Dataset already extracted at:\", drive_extract_path)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Copy dataset to local /content (faster training)\n",
    "# ---------------------------\n",
    "if not os.path.exists(local_dataset_path):\n",
    "    print(\"Copying dataset to Colab local storage (/content)...\")\n",
    "    !cp -r \"$drive_extract_path\" \"$local_dataset_path\"\n",
    "else:\n",
    "    print(\"Dataset already available in Colab local storage.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Step 4: Define dataset paths for training\n",
    "# ---------------------------\n",
    "TRAIN_IMG_DIR = os.path.join(local_dataset_path, \"train\", \"images\")\n",
    "TRAIN_LBL_DIR = os.path.join(local_dataset_path, \"train\", \"labels\")\n",
    "TEST_IMG_DIR  = os.path.join(local_dataset_path, \"test\", \"images\")\n",
    "\n",
    "print(\"Train images:\", TRAIN_IMG_DIR)\n",
    "print(\"Train labels:\", TRAIN_LBL_DIR)\n",
    "print(\"Test images:\", TEST_IMG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aef589",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a82472",
   "metadata": {},
   "source": [
    "### Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f14be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crowd_counts(\n",
    "    label_dir: str\n",
    ") -> Dict[str, int]:\n",
    "    \"\"\"Load crowd counts from JSON label files.\"\"\"\n",
    "    crowd_counts = {}\n",
    "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.json')]\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        img_name = label_file.replace('.json', '.jpg')\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            crowd_counts[img_name] = data.get('human_num', 0)\n",
    "    \n",
    "    return crowd_counts\n",
    "\n",
    "def create_density_map(\n",
    "    annotations: List[Tuple[int, int]], \n",
    "    img_height: int, \n",
    "    img_width: int, \n",
    "    sigma: float = 15.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create density map from point annotations using Gaussian kernels.\n",
    "    \"\"\"\n",
    "    density_map = np.zeros((img_height, img_width), dtype=np.float32)\n",
    "    \n",
    "    for x, y in annotations:\n",
    "        if 0 <= x < img_width and 0 <= y < img_height:\n",
    "            density_map[y, x] = 1.0\n",
    "    \n",
    "    # Apply Gaussian filter to create density map\n",
    "    density_map = scipy.ndimage.gaussian_filter(density_map, sigma=sigma)\n",
    "    \n",
    "    return density_map\n",
    "\n",
    "def load_annotations_and_density(\n",
    "    label_dir: str, \n",
    "    img_dir: str\n",
    ") -> Dict[str, Tuple[int, np.ndarray]]:\n",
    "    \"\"\"Load annotations and create density maps for training.\"\"\"\n",
    "    data_dict = {}\n",
    "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.json')]\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        img_name = label_file.replace('.json', '.jpg')\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "            \n",
    "        # Load image to get dimensions\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_height, img_width = img.shape[:2]\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            count = data.get('human_num', 0)\n",
    "            \n",
    "            # Get point annotations (assuming they exist in the JSON)\n",
    "            points = []\n",
    "            if 'annotations' in data:\n",
    "                for ann in data['annotations']:\n",
    "                    if 'bbox' in ann:\n",
    "                        # Convert bbox to center point\n",
    "                        x, y, w, h = ann['bbox']\n",
    "                        center_x = x + w // 2\n",
    "                        center_y = y + h // 2\n",
    "                        points.append((center_x, center_y))\n",
    "            \n",
    "            # Create density map\n",
    "            density_map = create_density_map(points, img_height, img_width)\n",
    "            \n",
    "            # Resize density map to quarter resolution for training efficiency\n",
    "            target_height = img_height // 4\n",
    "            target_width = img_width // 4\n",
    "            density_map = cv2.resize(density_map, (target_width, target_height))\n",
    "            \n",
    "            data_dict[img_name] = (count, density_map)\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "# Load crowd counts and create density maps\n",
    "crowd_counts = load_crowd_counts(TRAIN_LBL_DIR)\n",
    "print(f\"Loaded {len(crowd_counts)} crowd count labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457350c5",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation transforms\n",
    "train_transforms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=512),\n",
    "    A.PadIfNeeded(min_height=512, min_width=512, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "    A.RandomResizedCrop(height=512, width=512, scale=(0.7, 1.0), ratio=(0.75, 1.33)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.7),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], additional_targets={'density': 'mask'})\n",
    "\n",
    "val_transforms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=512),\n",
    "    A.PadIfNeeded(min_height=512, min_width=512, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], additional_targets={'density': 'mask'})\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=512),\n",
    "    A.PadIfNeeded(min_height=512, min_width=512, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c420bd",
   "metadata": {},
   "source": [
    "# 3. Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridCrowdDataset(Dataset):\n",
    "    \"\"\"Dataset for hybrid density + count regression training.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        image_dir: str, \n",
    "        crowd_counts: Dict[str, int], \n",
    "        image_files: List[str], \n",
    "        transform=None, \n",
    "        use_density_maps: bool = False\n",
    "    ):\n",
    "        self.image_dir = image_dir\n",
    "        self.crowd_counts = crowd_counts\n",
    "        self.image_files = [f for f in image_files if f in crowd_counts]\n",
    "        self.transform = transform\n",
    "        self.use_density_maps = use_density_maps\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx: int)  :\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Create dummy density map (since we don't have point annotations)\n",
    "        # For now, create a simple uniform density map\n",
    "        count = self.crowd_counts[img_name]\n",
    "        img_height, img_width = image.shape[:2]\n",
    "        \n",
    "        # Create simple density map: distribute count uniformly\n",
    "        density_map = np.full(\n",
    "            (img_height // 4, img_width // 4), \n",
    "            count / ((img_height // 4) * (img_width // 4)), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, density=density_map)\n",
    "            image = augmented['image']\n",
    "            density_map = augmented['density']\n",
    "        \n",
    "        density_tensor = torch.tensor(density_map, dtype=torch.float32).unsqueeze(0)\n",
    "        count_tensor = torch.tensor(count, dtype=torch.float32)\n",
    "\n",
    "        return image, density_tensor, count_tensor\n",
    "\n",
    "# Create train-val split\n",
    "image_files = list(crowd_counts.keys())\n",
    "train_files, val_files = train_test_split(\n",
    "    image_files, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = HybridCrowdDataset(\n",
    "    TRAIN_IMG_DIR, \n",
    "    crowd_counts, \n",
    "    train_files, \n",
    "    train_transforms\n",
    ")\n",
    "val_dataset = HybridCrowdDataset(\n",
    "    TRAIN_IMG_DIR, \n",
    "    crowd_counts, \n",
    "    val_files, \n",
    "    val_transforms\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(train_dataset)} images\")\n",
    "print(f\"Validation set: {len(val_dataset)} images\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7314c",
   "metadata": {},
   "source": [
    "# 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ac3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCountingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCountingNet, self).__init__()\n",
    "        \n",
    "        # Simple CNN backbone\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Density regression head\n",
    "        self.density_head = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 1, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Count regression head\n",
    "        self.count_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.features(x)\n",
    "        \n",
    "        # Density map prediction\n",
    "        density = self.density_head(features)\n",
    "        # Upsample to quarter resolution\n",
    "        density = F.interpolate(\n",
    "            density, \n",
    "            scale_factor=8, \n",
    "            mode='bilinear', \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        # Count prediction\n",
    "        count = self.count_head(features).squeeze()\n",
    "        \n",
    "        return density, count\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleCountingNet().to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"SimpleCountingNet created:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d4fa2",
   "metadata": {},
   "source": [
    "# 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8968b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridLoss(nn.Module):\n",
    "    \"\"\"Hybrid loss combining density map MSE and count regression.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        density_weight: float = 1.0, \n",
    "        count_weight: float = 10.0\n",
    "    ):\n",
    "        super(HybridLoss, self).__init__()\n",
    "        self.density_weight = density_weight\n",
    "        self.count_weight = count_weight\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        pred_density: torch.Tensor,\n",
    "        pred_count: torch.Tensor,\n",
    "        true_density: torch.Tensor,\n",
    "        true_count: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # Density map loss (MSE)\n",
    "        density_loss = self.mse_loss(pred_density, true_density)\n",
    "        \n",
    "        # Count regression loss (L1)\n",
    "        count_loss = self.l1_loss(pred_count, true_count)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = self.density_weight * density_loss + self.count_weight * count_loss\n",
    "        \n",
    "        return total_loss, density_loss, count_loss\n",
    "\n",
    "def train_hybrid_model(\n",
    "    model: nn.Module, \n",
    "    train_loader: DataLoader, \n",
    "    val_loader: DataLoader, \n",
    "    num_epochs: int = 50, \n",
    "    learning_rate: float = 0.001\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"Train the hybrid model with both density and count supervision.\"\"\"\n",
    "    \n",
    "    criterion = HybridLoss(density_weight=1.0, count_weight=10.0)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=learning_rate, \n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min', \n",
    "        factor=0.5, \n",
    "        patience=5\n",
    "    )\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_density_loss': [], 'val_density_loss': [],\n",
    "        'train_count_loss': [], 'val_count_loss': [],\n",
    "        'train_mae': [], 'val_mae': []\n",
    "    }\n",
    "    \n",
    "    best_val_mae = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 10\n",
    "    \n",
    "    print(\"Starting hybrid training...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_density_loss = 0.0\n",
    "        train_count_loss = 0.0\n",
    "        train_mae = 0.0\n",
    "        \n",
    "        for batch_idx, (images, density_maps, counts) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            density_maps = density_maps.to(device)\n",
    "            counts = counts.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_density, pred_count = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            total_loss, density_loss, count_loss = criterion(pred_density, pred_count, density_maps, counts)\n",
    "            \n",
    "            # Backward pass\n",
    "            total_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate losses\n",
    "            train_loss += total_loss.item()\n",
    "            train_density_loss += density_loss.item()\n",
    "            train_count_loss += count_loss.item()\n",
    "            train_mae += nn.L1Loss()(pred_count, counts).item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_density_loss = 0.0\n",
    "        val_count_loss = 0.0\n",
    "        val_mae = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, density_maps, counts in val_loader:\n",
    "                images = images.to(device)\n",
    "                density_maps = density_maps.to(device)\n",
    "                counts = counts.to(device)\n",
    "                \n",
    "                pred_density, pred_count = model(images)\n",
    "                total_loss, density_loss, count_loss = criterion(pred_density, pred_count, density_maps, counts)\n",
    "                \n",
    "                val_loss += total_loss.item()\n",
    "                val_density_loss += density_loss.item()\n",
    "                val_count_loss += count_loss.item()\n",
    "                val_mae += nn.L1Loss()(pred_count, counts).item()\n",
    "        \n",
    "        # Calculate averages\n",
    "        train_loss /= len(train_loader)\n",
    "        train_density_loss /= len(train_loader)\n",
    "        train_count_loss /= len(train_loader)\n",
    "        train_mae /= len(train_loader)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_density_loss /= len(val_loader)\n",
    "        val_count_loss /= len(val_loader)\n",
    "        val_mae /= len(val_loader)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_mae)\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_density_loss'].append(train_density_loss)\n",
    "        history['val_density_loss'].append(val_density_loss)\n",
    "        history['train_count_loss'].append(train_count_loss)\n",
    "        history['val_count_loss'].append(val_count_loss)\n",
    "        history['train_mae'].append(train_mae)\n",
    "        history['val_mae'].append(val_mae)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f'Epoch {epoch+1:3d}/{num_epochs} | '\n",
    "                  f'Loss: {train_loss:.4f}/{val_loss:.4f} | '\n",
    "                  f'MAE: {train_mae:.4f}/{val_mae:.4f} | '\n",
    "                  f'Count Loss: {train_count_loss:.4f}/{val_count_loss:.4f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_mae < best_val_mae:\n",
    "            best_val_mae = val_mae\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), 'best_hybrid_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_hybrid_model.pth'))\n",
    "    print(f\"\\nTraining completed! Best validation MAE: {best_val_mae:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the model\n",
    "training_history = train_hybrid_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    num_epochs=50, \n",
    "    learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcbb50a",
   "metadata": {},
   "source": [
    "# 5. Evaluation and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdab63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid_model(\n",
    "    model: nn.Module, \n",
    "    data_loader: DataLoader, \n",
    "    dataset_name=\"Dataset\"\n",
    "):\n",
    "    \"\"\"Comprehensive evaluation of hybrid model.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_pred_counts = []\n",
    "    all_true_counts = []\n",
    "    all_pred_densities = []\n",
    "    all_true_densities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, density_maps, counts in data_loader:\n",
    "            images = images.to(device)\n",
    "            density_maps = density_maps.to(device)\n",
    "            counts = counts.to(device)\n",
    "            \n",
    "            pred_density, pred_count = model(images)\n",
    "            \n",
    "            all_pred_counts.extend(pred_count.cpu().numpy())\n",
    "            all_true_counts.extend(counts.cpu().numpy())\n",
    "            all_pred_densities.extend(pred_density.cpu().numpy())\n",
    "            all_true_densities.extend(density_maps.cpu().numpy())\n",
    "    \n",
    "    pred_counts = np.array(all_pred_counts)\n",
    "    true_counts = np.array(all_true_counts)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(true_counts, pred_counts)\n",
    "    mse = mean_squared_error(true_counts, pred_counts)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Additional metrics\n",
    "    mape = np.mean(np.abs((true_counts - pred_counts) / (true_counts + 1e-8))) * 100\n",
    "    correlation = np.corrcoef(true_counts, pred_counts)[0, 1]\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Evaluation Results:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"MAE (Count):     {mae:.4f}\")\n",
    "    print(f\"MSE (Count):     {mse:.4f}\")\n",
    "    print(f\"RMSE (Count):    {rmse:.4f}\")\n",
    "    print(f\"MAPE (%):        {mape:.2f}\")\n",
    "    print(f\"Correlation:     {correlation:.4f}\")\n",
    "    print(f\"Mean True Count: {np.mean(true_counts):.2f}\")\n",
    "    print(f\"Mean Pred Count: {np.mean(pred_counts):.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mape': mape,\n",
    "        'correlation': correlation,\n",
    "        'pred_counts': pred_counts,\n",
    "        'true_counts': true_counts\n",
    "    }\n",
    "\n",
    "# Evaluate on both sets\n",
    "train_results = evaluate_hybrid_model(model, train_loader, \"Training Set\")\n",
    "val_results = evaluate_hybrid_model(model, val_loader, \"Validation Set\")\n",
    "\n",
    "# Plot training history\n",
    "def plot_hybrid_training_history(history):\n",
    "    \"\"\"Plot training history for hybrid model.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # Total loss\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss', color='red')\n",
    "    axes[0, 0].set_title('Total Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Count loss\n",
    "    axes[0, 1].plot(history['train_count_loss'], label='Train Count Loss', color='blue')\n",
    "    axes[0, 1].plot(history['val_count_loss'], label='Val Count Loss', color='red')\n",
    "    axes[0, 1].set_title('Count Regression Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Density loss\n",
    "    axes[0, 2].plot(history['train_density_loss'], label='Train Density Loss', color='blue')\n",
    "    axes[0, 2].plot(history['val_density_loss'], label='Val Density Loss', color='red')\n",
    "    axes[0, 2].set_title('Density Map Loss')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Loss')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE\n",
    "    axes[1, 0].plot(history['train_mae'], label='Train MAE', color='blue')\n",
    "    axes[1, 0].plot(history['val_mae'], label='Val MAE', color='red')\n",
    "    axes[1, 0].set_title('Mean Absolute Error')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('MAE')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Predictions vs targets\n",
    "    axes[1, 1].scatter(val_results['true_counts'], val_results['pred_counts'], alpha=0.6)\n",
    "    axes[1, 1].plot([0, max(val_results['true_counts'])], [0, max(val_results['true_counts'])], 'r--')\n",
    "    axes[1, 1].set_xlabel('True Count')\n",
    "    axes[1, 1].set_ylabel('Predicted Count')\n",
    "    axes[1, 1].set_title('Validation: Predictions vs True')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Error distribution\n",
    "    errors = val_results['pred_counts'] - val_results['true_counts']\n",
    "    axes[1, 2].hist(errors, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 2].axvline(x=0, color='red', linestyle='--')\n",
    "    axes[1, 2].set_xlabel('Prediction Error')\n",
    "    axes[1, 2].set_ylabel('Frequency')\n",
    "    axes[1, 2].set_title('Error Distribution')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_hybrid_training_history(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842e75f",
   "metadata": {},
   "source": [
    "# 6. Visualization of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcad622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hybrid_predictions(\n",
    "    model, \n",
    "    dataset, \n",
    "    num_samples=8\n",
    "):\n",
    "    \"\"\"Visualize density maps and count predictions.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get sample data\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(4, num_samples//2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            if i >= num_samples//2:\n",
    "                break\n",
    "                \n",
    "            image, true_density, true_count = dataset[idx]\n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            \n",
    "            pred_density, pred_count = model(image_batch)\n",
    "            \n",
    "            # Denormalize image for visualization\n",
    "            img_viz = image.clone()\n",
    "            img_viz = img_viz * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            img_viz = torch.clamp(img_viz, 0, 1).permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Original image\n",
    "            axes[i*4].imshow(img_viz)\n",
    "            axes[i*4].set_title(f'Original\\nTrue: {true_count:.0f}, Pred: {pred_count.item():.1f}')\n",
    "            axes[i*4].axis('off')\n",
    "            \n",
    "            # True density map\n",
    "            axes[i*4 + 1].imshow(true_density.squeeze().numpy(), cmap='hot')\n",
    "            axes[i*4 + 1].set_title('True Density')\n",
    "            axes[i*4 + 1].axis('off')\n",
    "            \n",
    "            # Predicted density map\n",
    "            pred_density_viz = pred_density.squeeze().cpu().numpy()\n",
    "            axes[i*4 + 2].imshow(pred_density_viz, cmap='hot')\n",
    "            axes[i*4 + 2].set_title('Predicted Density')\n",
    "            axes[i*4 + 2].axis('off')\n",
    "            \n",
    "            # Density difference\n",
    "            diff = pred_density_viz - true_density.squeeze().numpy()\n",
    "            im = axes[i*4 + 3].imshow(diff, cmap='RdBu', vmin=-np.max(np.abs(diff)), vmax=np.max(np.abs(diff)))\n",
    "            axes[i*4 + 3].set_title('Difference')\n",
    "            axes[i*4 + 3].axis('off')\n",
    "            plt.colorbar(im, ax=axes[i*4 + 3])\n",
    "    \n",
    "    plt.suptitle('Hybrid Model Predictions: Density Maps + Counts', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample predictions\n",
    "visualize_hybrid_predictions(model, val_dataset, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a79bde7",
   "metadata": {},
   "source": [
    "# 7. Test Set Prediction and Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    \"\"\"Dataset for test images.\"\"\"\n",
    "    def __init__(self, image_dir: str, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')],\n",
    "                                 key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image, img_name\n",
    "\n",
    "def generate_hybrid_test_predictions(\n",
    "    model, \n",
    "    test_dir, \n",
    "    output_file='hybrid_submission.csv'\n",
    ") -> DataFrame:\n",
    "    \"\"\"Generate test predictions using the hybrid model.\"\"\"\n",
    "    print(\"Generating test predictions with hybrid model...\")\n",
    "    \n",
    "    test_dataset = TestDataset(test_dir, test_transforms)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=16, \n",
    "        shuffle=False, \n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    image_names = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, names in test_loader:\n",
    "            images = images.to(device)\n",
    "            pred_density, pred_count = model(images)\n",
    "            \n",
    "            # Use count predictions for submission\n",
    "            batch_preds = pred_count.cpu().numpy()\n",
    "            predictions.extend([max(0, int(round(pred))) for pred in batch_preds])\n",
    "            image_names.extend(names)\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'image_id': image_names,\n",
    "        'predicted_count': predictions\n",
    "    })\n",
    "    \n",
    "    # Sort by image_id\n",
    "    submission_df['sort_key'] = submission_df['image_id'].apply(lambda x: int(os.path.splitext(x)[0]))\n",
    "    submission_df = submission_df.sort_values('sort_key').drop('sort_key', axis=1).reset_index(drop=True)\n",
    "    \n",
    "    # Save submission\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Submission saved to {output_file}\")\n",
    "    print(f\"Predictions for {len(submission_df)} test images\")\n",
    "    \n",
    "    # Statistics\n",
    "    pred_counts = submission_df['predicted_count'].values\n",
    "    print(f\"\\nTest Predictions Statistics:\")\n",
    "    print(f\"Min: {pred_counts.min()}\")\n",
    "    print(f\"Max: {pred_counts.max()}\")\n",
    "    print(f\"Mean: {pred_counts.mean():.2f}\")\n",
    "    print(f\"Median: {np.median(pred_counts):.2f}\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# Generate test predictions\n",
    "submission_df = generate_hybrid_test_predictions(model, TEST_IMG_DIR)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 10 rows of submission:\")\n",
    "print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3435a8d",
   "metadata": {},
   "source": [
    "# 8. Final Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"HYBRID CROWD COUNTING MODEL - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nModel Architecture: SimpleCountingNet\")\n",
    "print(f\"- CNN Backbone: Custom 4-layer CNN\")\n",
    "print(f\"- Dual outputs: Density maps + Direct count regression\")\n",
    "print(f\"- Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"- Training images: {len(train_dataset)}\")\n",
    "print(f\"- Validation images: {len(val_dataset)}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Loss function: Hybrid (Density MSE + Count L1)\")\n",
    "\n",
    "print(f\"\\nFinal Performance Metrics:\")\n",
    "print(f\"- Training MAE: {train_results['mae']:.4f}\")\n",
    "print(f\"- Validation MAE: {val_results['mae']:.4f}\")\n",
    "print(f\"- Validation RMSE: {val_results['rmse']:.4f}\")\n",
    "print(f\"- Validation Correlation: {val_results['correlation']:.4f}\")\n",
    "\n",
    "print(f\"\\nKey Advantages of Hybrid Approach:\")\n",
    "print(f\"- Combines spatial density information with global count regression\")\n",
    "print(f\"- Density maps provide spatial understanding\")\n",
    "print(f\"- Count regression ensures accurate total predictions\")\n",
    "print(f\"- Mutual supervision improves both predictions\")\n",
    "\n",
    "print(f\"\\nTest Set Predictions:\")\n",
    "print(f\"- Generated predictions for {len(submission_df)} test images\")\n",
    "print(f\"- Mean predicted count: {submission_df['predicted_count'].mean():.2f}\")\n",
    "print(f\"- Prediction range: {submission_df['predicted_count'].min()} to {submission_df['predicted_count'].max()}\")\n",
    "\n",
    "print(f\"\\nNext Steps for Improvement:\")\n",
    "print(f\"- Implement proper point annotations for better density maps\")\n",
    "print(f\"- Add attention mechanisms to focus on crowd regions\")\n",
    "print(f\"- Experiment with different loss function weights\")\n",
    "print(f\"- Use pretrained backbones (ResNet, EfficientNet)\")\n",
    "print(f\"- Implement multi-scale training and testing\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
