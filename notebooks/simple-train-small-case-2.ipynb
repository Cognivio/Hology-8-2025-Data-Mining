{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6bef876",
   "metadata": {},
   "source": [
    "# Improved People Counting with Density Maps\n",
    "This notebook demonstrates an improved approach for counting people in images by switching from bounding box detection to density map estimation. This method is more effective for counting tasks, especially with a limited dataset.\n",
    "\n",
    "**Key Improvements:**\n",
    "1.  **Task Formulation**: Changed from single-object detection to density map regression.\n",
    "2.  **Data Preprocessing**: A new `Dataset` class generates ground truth density maps from head coordinates provided in JSON files.\n",
    "3.  **Model Architecture**: Replaced the simple detector with a Fully Convolutional Network (FCN) suitable for producing density maps.\n",
    "4.  **Loss Function**: Using Mean Squared Error (MSE) between the predicted and ground truth density maps.\n",
    "5.  **Evaluation**: Implemented Mean Absolute Error (MAE) to measure counting accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfca240",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b525b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0509b",
   "metadata": {},
   "source": [
    "## 2. Dataset and Density Map Generation\n",
    "We define a custom dataset that reads images and their corresponding JSON labels. For each image, it generates a ground truth density map by applying a Gaussian kernel to each annotated head position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrowdCountingDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, max_samples=50, img_size=224, downscale_factor=16, sigma=4):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_size = img_size\n",
    "        self.downscale_factor = downscale_factor\n",
    "        self.sigma = sigma\n",
    "\n",
    "        all_images = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
    "        self.image_files = all_images[:max_samples]\n",
    "        self.labels = self._load_labels()\n",
    "\n",
    "        print(f\"Using {len(self.image_files)} images for training.\")\n",
    "\n",
    "    def _load_labels(self):\n",
    "        labels = {}\n",
    "        for img_file in self.image_files:\n",
    "            label_file = img_file.replace('.jpg', '.json')\n",
    "            label_path = os.path.join(self.label_dir, label_file)\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    labels[img_file] = data\n",
    "        return labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "\n",
    "        # Load and resize image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        orig_h, orig_w = image.shape[:2]\n",
    "        image = cv2.resize(image, (self.img_size, self.img_size))\n",
    "        image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        # Generate density map\n",
    "        output_size = self.img_size // self.downscale_factor\n",
    "        density_map = np.zeros((output_size, output_size), dtype=np.float32)\n",
    "\n",
    "        label_data = self.labels.get(img_name)\n",
    "        if label_data and label_data['human_num'] > 0:\n",
    "            points = np.array(label_data['points'])\n",
    "            for x, y in points:\n",
    "                # Scale coordinates to the output map size\n",
    "                scaled_x = int((x / orig_w) * output_size)\n",
    "                scaled_y = int((y / orig_h) * output_size)\n",
    "                if 0 <= scaled_x < output_size and 0 <= scaled_y < output_size:\n",
    "                    density_map[scaled_y, scaled_x] = 1.0\n",
    "\n",
    "        # Apply Gaussian filter to create the density map\n",
    "        density_map = gaussian_filter(density_map, sigma=self.sigma / self.downscale_factor)\n",
    "        density_map_tensor = torch.from_numpy(density_map).unsqueeze(0) # Add channel dimension\n",
    "\n",
    "        return image_tensor, density_map_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce404225",
   "metadata": {},
   "source": [
    "## 3. Fully Convolutional Network (FCN) for Density Estimation\n",
    "This FCN model uses a simple CNN backbone to extract features and then a `1x1` convolution to produce a single-channel density map. The output map is 1/16th the size of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f87c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensityFCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DensityFCN, self).__init__()\n",
    "        # Backbone: Feature extractor\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 224 -> 112\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 112 -> 56\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 56 -> 28\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 28 -> 14\n",
    "        )\n",
    "        # Head: Density map predictor\n",
    "        self.head = nn.Conv2d(128, 1, 1) # 1x1 conv to produce 1-channel map\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        # Use ReLU to ensure density is non-negative\n",
    "        return torch.relu(x)\n",
    "\n",
    "# Initialize model\n",
    "model = DensityFCN().to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\"Model architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6fb4d2",
   "metadata": {},
   "source": [
    "## 4. Load Data and Set Up Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths (assuming data is in a 'data' folder in the project root)\n",
    "BASE_DIR = '../data/penyisihan-hology-8-0-2025-data-mining'\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_DIR, 'train', 'images')\n",
    "TRAIN_LBL_DIR = os.path.join(BASE_DIR, 'train', 'labels')\n",
    "TEST_IMG_DIR = os.path.join(BASE_DIR, 'test', 'images')\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = CrowdCountingDataset(\n",
    "    image_dir=TRAIN_IMG_DIR,\n",
    "    label_dir=TRAIN_LBL_DIR,\n",
    "    max_samples=50, # Using 50 samples as requested\n",
    "    img_size=224,\n",
    "    downscale_factor=16\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss() # Pixel-wise MSE for density map regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03251ec8",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7693f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100 # Increased epochs for better convergence on small dataset\n",
    "training_losses = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for images, density_maps in train_loader:\n",
    "        images = images.to(device)\n",
    "        density_maps = density_maps.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        pred_density_maps = model(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(pred_density_maps, density_maps)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    training_losses.append(avg_loss)\n",
    "\n",
    "    if (epoch + 1) % 20 == 0 or epoch == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}')\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(training_losses)\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc5052c",
   "metadata": {},
   "source": [
    "## 6. Evaluation on Test Set\n",
    "We now evaluate the trained model on the test images. We define a function to predict the count for a single image and then calculate the Mean Absolute Error (MAE) across a sample of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_count(model, image_path, device, img_size=224):\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    resized_image = cv2.resize(image, (img_size, img_size))\n",
    "    input_tensor = torch.from_numpy(resized_image).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_density_map = model(input_tensor)\n",
    "\n",
    "    # The predicted count is the sum of the density map\n",
    "    predicted_count = pred_density_map.sum().item()\n",
    "    \n",
    "    return image, predicted_count, pred_density_map.squeeze().cpu().numpy()\n",
    "\n",
    "def get_ground_truth_count(image_name, label_dir):\n",
    "    label_file = image_name.replace('.jpg', '.json')\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "    if not os.path.exists(label_path):\n",
    "        # For test set, we might not have labels. We'll use train labels for MAE calculation.\n",
    "        return 0\n",
    "    with open(label_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['human_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating model on training images (to check learning)...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "evaluation_results = []\n",
    "sample_images_for_eval = train_dataset.image_files[:10] # Use first 10 training images for eval\n",
    "\n",
    "for img_name in sample_images_for_eval:\n",
    "    img_path = os.path.join(TRAIN_IMG_DIR, img_name)\n",
    "    \n",
    "    # Get ground truth\n",
    "    true_count = get_ground_truth_count(img_name, TRAIN_LBL_DIR)\n",
    "    \n",
    "    # Get prediction\n",
    "    original_image, pred_count, pred_map = predict_count(model, img_path, device)\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        'image_name': img_name,\n",
    "        'true_count': true_count,\n",
    "        'pred_count': pred_count\n",
    "    })\n",
    "    \n",
    "    # Visualize first 3 images\n",
    "    if len(evaluation_results) <= 3:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(original_image)\n",
    "        ax1.set_title(f'Original Image: {img_name}')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        im = ax2.imshow(pred_map, cmap='jet')\n",
    "        ax2.set_title(f'Predicted Density Map (Count: {pred_count:.2f})\\nGround Truth: {true_count}')\n",
    "        ax2.axis('off')\n",
    "        fig.colorbar(im, ax=ax2)\n",
    "        plt.show()\n",
    "\n",
    "# Calculate and display MAE\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "mae = (eval_df['pred_count'] - eval_df['true_count']).abs().mean()\n",
    "\n",
    "print(\"\\nEvaluation Results on Training Sample:\")\n",
    "print(eval_df)\n",
    "print(f\"\\nMean Absolute Error (MAE): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c280cb1a",
   "metadata": {},
   "source": [
    "## 7. Final Submission Generation\n",
    "Finally, we run predictions on the actual test set and generate a `submission.csv` file in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9ba3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating submission file for the test set...\")\n",
    "\n",
    "test_images = sorted([f for f in os.listdir(TEST_IMG_DIR) if f.endswith('.jpg')])\n",
    "submission_data = []\n",
    "\n",
    "for img_name in test_images:\n",
    "    img_path = os.path.join(TEST_IMG_DIR, img_name)\n",
    "    _, pred_count, _ = predict_count(model, img_path, device)\n",
    "    \n",
    "    submission_data.append({\n",
    "        'id': img_name,\n",
    "        'human_num': int(round(pred_count))\n",
    "    })\n",
    "\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' created successfully.\")\n",
    "print(\"\\nFirst 5 rows of submission:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
